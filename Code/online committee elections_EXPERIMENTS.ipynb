{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYRWI_7Z-bbQ"
      },
      "source": [
        "# Fairness in the Multi-Secretary Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqnIhmPM0mHN"
      },
      "source": [
        "## Experiment 1: Pabulib Instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EH9yT7gexWvU"
      },
      "outputs": [],
      "source": [
        "run_experiment_one()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO_TinTdxWvV"
      },
      "source": [
        "## Experiment 2: Sushi and MovieLens Datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXNLaJQjxWvV"
      },
      "source": [
        "### Sushi Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PL1Y9_5HxWvV"
      },
      "outputs": [],
      "source": [
        "run_experiment_two_A()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIDgJ5D7xWvV"
      },
      "source": [
        "### MovieLens Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8BN8cxixWvV"
      },
      "outputs": [],
      "source": [
        "run_experiment_two_B()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skDIg9QbxWvV"
      },
      "source": [
        "## Experiment 3: Sampled Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlot-1MwxWvV"
      },
      "source": [
        "### Impartial Culture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6363UPg2xWvV"
      },
      "outputs": [],
      "source": [
        "run_experiment_three_A()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhrYpQm-xWvW"
      },
      "source": [
        "### Mallows Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S594GVB3xWvW"
      },
      "outputs": [],
      "source": [
        "run_experiment_three_B()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyouccaaxWvW"
      },
      "source": [
        "### Normalized Mallows Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrtLe0kbxWvW"
      },
      "outputs": [],
      "source": [
        "run_experiment_three_C()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3SgbTuDxWvW"
      },
      "source": [
        "## Experiment 4: Polarized Instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYtywSjYxWvW"
      },
      "outputs": [],
      "source": [
        "run_experiment_four()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjktzmZyxWvW"
      },
      "source": [
        "# -----------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEzCVuNwxWvW"
      },
      "source": [
        "# Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBxnA8bNxWvW"
      },
      "source": [
        "# Libraries and Logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHjxFMJFxWvW",
        "outputId": "77593e32-915b-48f3-f74b-8b0d70b55481"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import copy\n",
        "import csv\n",
        "import itertools\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "from typing import Dict, Set, List, Optional, Tuple, Union\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "# Un-comment these lines if running in an environment where these are not installed\n",
        "# !pip install colorama\n",
        "# !pip install prefsampling\n",
        "\n",
        "from colorama import Fore, Style\n",
        "from prefsampling.ordinal import mallows, norm_mallows\n",
        "\n",
        "# Configure Logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s [%(threadName)s] %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler(\"output.log\"),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc_-rarQUTyf"
      },
      "source": [
        "# Election Rules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9ha4JilA_tG"
      },
      "outputs": [],
      "source": [
        "def greedy(utilities: np.ndarray, k: int, seed: int = None, exact_k: bool = True, return_free_riders: bool = False):\n",
        "    \"\"\"\n",
        "    Greedy Budgeting Algorithm.\n",
        "    \n",
        "    Args:\n",
        "        utilities: (n x m) utility matrix.\n",
        "        k: Target committee size.\n",
        "        seed: Random seed for tie-breaking/shuffling.\n",
        "        exact_k: If True, ensures exactly k candidates are returned by filling with remaining candidates.\n",
        "        return_free_riders: If True, returns a tuple (selected, free_riders).\n",
        "    \"\"\"\n",
        "    n, m = utilities.shape\n",
        "    # Each voter gets an equal budget share of k/n\n",
        "    budget = np.ones(n) * (k / n)\n",
        "    selected = []\n",
        "    free_riders = []\n",
        "\n",
        "    candidates = list(range(m))\n",
        "    if seed is not None:\n",
        "        rng = random.Random(seed)\n",
        "        rng.shuffle(candidates)\n",
        "    else:\n",
        "        random.shuffle(candidates)\n",
        "        \n",
        "    remaining_candidates = candidates.copy()\n",
        "\n",
        "    for c in candidates:\n",
        "        if c in selected:\n",
        "            continue\n",
        "\n",
        "        remaining_candidates.remove(c)\n",
        "\n",
        "        # Check if we need to fill the committee to reach size k immediately\n",
        "        if exact_k:\n",
        "            if len(selected) == k - len(remaining_candidates):\n",
        "                selected.extend(remaining_candidates)\n",
        "                free_riders = remaining_candidates.copy()\n",
        "                break\n",
        "\n",
        "        # Identify supporters who have utility and remaining budget\n",
        "        supporters = [i for i in range(n) if utilities[i, c] > 0 and budget[i] > 0]\n",
        "        if not supporters:\n",
        "            continue\n",
        "\n",
        "        supporters_budget = sum(budget[i] for i in supporters)\n",
        "        if supporters_budget < 1.0 - 1e-10:\n",
        "            continue  # Not enough budget to purchase candidate c (cost = 1.0)\n",
        "\n",
        "        selected.append(c)\n",
        "\n",
        "        # Distribute cost (1.0) equally among supporters, capped by their individual budget\n",
        "        remaining_cost = 1.0\n",
        "        contribs = {i: 0.0 for i in supporters}\n",
        "\n",
        "        while remaining_cost > 1e-10:\n",
        "            active = [i for i in supporters if budget[i] - contribs[i] > 1e-10]\n",
        "            if not active:\n",
        "                break\n",
        "\n",
        "            share = remaining_cost / len(active)\n",
        "            for i in active:\n",
        "                pay = min(share, budget[i] - contribs[i])\n",
        "                contribs[i] += pay\n",
        "                remaining_cost -= pay\n",
        "\n",
        "        # Deduct the calculated contributions from voter budgets\n",
        "        for i in supporters:\n",
        "            budget[i] -= contribs[i]\n",
        "\n",
        "        if len(selected) == k:\n",
        "            break\n",
        "\n",
        "    if return_free_riders:\n",
        "        return selected, free_riders\n",
        "    else:\n",
        "        return selected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqWlomw-BLeZ"
      },
      "outputs": [],
      "source": [
        "# --- Method of Equal Shares (Offline) Classes and Functions ---\n",
        "\n",
        "class Voter:\n",
        "    def __init__(self, id: str):\n",
        "        self.id = id\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(self.id)\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return self.id == other.id\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"v({self.id})\"\n",
        "\n",
        "\n",
        "class Candidate:\n",
        "    def __init__(self, id: str):\n",
        "        self.id = id\n",
        "        self.cost = 1  # Unit cost assumption\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(self.id)\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return self.id == other.id\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"c({self.id})\"\n",
        "\n",
        "\n",
        "class Election:\n",
        "    def __init__(self, voters: Set[Voter] = None, profile: Dict[Candidate, Dict[Voter, int]] = None, budget: int = 0):\n",
        "        self.voters = voters if voters else set()\n",
        "        self.profile = profile if profile else {}  # Map: candidate -> voter -> utility\n",
        "        self.budget = budget\n",
        "\n",
        "\n",
        "def _utilitarian_greedy_internal(e: Election, W: set[Candidate]) -> set[Candidate]:\n",
        "    \"\"\"Internal helper to complete a committee using utilitarian greedy strategy.\"\"\"\n",
        "    costW = sum(c.cost for c in W)\n",
        "    remaining = set(c for c in e.profile if c not in W)\n",
        "    \n",
        "    # Rank remaining candidates by bang-per-buck (total utility / cost)\n",
        "    ranked = sorted(\n",
        "        remaining,\n",
        "        key=lambda c: (-sum(e.profile[c].values()) / c.cost, c.id)\n",
        "    )\n",
        "    \n",
        "    for c in ranked:\n",
        "        if costW + c.cost <= e.budget:\n",
        "            W.add(c)\n",
        "            costW += c.cost\n",
        "    return W\n",
        "\n",
        "\n",
        "def utilitarian_greedy(e: Election) -> set[Candidate]:\n",
        "    return _utilitarian_greedy_internal(e, set())\n",
        "\n",
        "\n",
        "def safe_division(x, y):\n",
        "    \"\"\"Safely divides x by y, handling small denominators.\"\"\"\n",
        "    if abs(y) < 1e-10:\n",
        "        return float('inf')\n",
        "    else:\n",
        "        return x / y\n",
        "\n",
        "\n",
        "def _mes_internal(e: Election, real_budget: int = 0) -> Tuple[Dict[Voter, float], Set[Candidate]]:\n",
        "    \"\"\"\n",
        "    Internal implementation of the Method of Equal Shares (MES).\n",
        "    Returns:\n",
        "        endow: Remaining budget per voter.\n",
        "        W: Set of winning candidates.\n",
        "    \"\"\"\n",
        "    W = set()\n",
        "    costW = 0\n",
        "    remaining = set(c for c in e.profile)\n",
        "    endow = {i: 1.0 * e.budget / len(e.voters) for i in e.voters}\n",
        "    \n",
        "    # rho represents the cost-per-utility unit required to elect a candidate\n",
        "    rho = {c: safe_division(c.cost, sum(e.profile[c].values())) for c in e.profile}\n",
        "\n",
        "    while True:\n",
        "        next_candidate = None\n",
        "        lowest_rho = float(\"inf\")\n",
        "        remaining_sorted = sorted(remaining, key=lambda c: (rho[c], c.id))\n",
        "\n",
        "        for c in remaining_sorted:\n",
        "            if rho[c] > lowest_rho + 1e-10:\n",
        "                break\n",
        "            if e.budget > 1e6: # Safety break for extremely large budgets\n",
        "                break\n",
        "                \n",
        "            # Check if supporters have enough current budget to afford the candidate\n",
        "            if sum(endow[i] for i in e.profile[c] if e.profile[c][i] > 0) + 1e-8 >= c.cost:\n",
        "                supporters_sorted = sorted(\n",
        "                    [i for i in e.profile[c]],\n",
        "                    key=lambda i: safe_division(endow[i], e.profile[c][i])\n",
        "                )\n",
        "                price = c.cost\n",
        "                util = sum(e.profile[c].values())\n",
        "\n",
        "                # Water-filling algorithm to find the clearing price (rho)\n",
        "                for i in supporters_sorted:\n",
        "                    if endow[i] * util >= price * e.profile[c][i]:\n",
        "                        break\n",
        "                    price -= endow[i]\n",
        "                    util -= e.profile[c][i]\n",
        "\n",
        "                if price > 1e-5:\n",
        "                    rho[c] = price / util\n",
        "                else:\n",
        "                    rho[c] = safe_division(endow[supporters_sorted[-1]], e.profile[c][supporters_sorted[-1]])\n",
        "\n",
        "                # Select candidate with the minimum rho (lexicographic tie-breaking)\n",
        "                if (rho[c] < lowest_rho or\n",
        "                    (abs(rho[c] - lowest_rho) < 1e-10 and (next_candidate is None or c.id < next_candidate.id))):\n",
        "                    next_candidate = c\n",
        "                    lowest_rho = rho[c]\n",
        "\n",
        "        if next_candidate is None:\n",
        "            break\n",
        "        else:\n",
        "            W.add(next_candidate)\n",
        "            costW += next_candidate.cost\n",
        "            remaining.remove(next_candidate)\n",
        "            # Deduct budget from supporters\n",
        "            for i in e.profile[next_candidate]:\n",
        "                endow[i] -= min(endow[i], lowest_rho * e.profile[next_candidate][i])\n",
        "            \n",
        "            # Optimization for 'increase-budget' completions\n",
        "            if real_budget: \n",
        "                if costW > real_budget:\n",
        "                    return None\n",
        "    return endow, W\n",
        "\n",
        "\n",
        "def _is_exhaustive(e: Election, W: set[Candidate]) -> bool:\n",
        "    \"\"\"Checks if budget is exhausted such that no other candidate can be afforded.\"\"\"\n",
        "    costW = sum(c.cost for c in W)\n",
        "    minRemainingCost = min([c.cost for c in e.profile if c not in W], default=math.inf)\n",
        "    return costW + minRemainingCost > e.budget\n",
        "\n",
        "\n",
        "def equal_shares(e: Election, completion: str = None) -> set[Candidate]:\n",
        "    \"\"\"\n",
        "    Executes Method of Equal Shares with optional completion strategies.\n",
        "    \n",
        "    strategies:\n",
        "        - 'binsearch': Binary search for optimal budget multiplier.\n",
        "        - 'utilitarian_greedy': Fills remainder with utilitarian greedy.\n",
        "        - 'add1': Incrementally increases budget.\n",
        "        - None: Standard MES.\n",
        "    \"\"\"\n",
        "    endow, W = _mes_internal(e)\n",
        "    if completion is None:\n",
        "        return W\n",
        "        \n",
        "    if completion == 'binsearch':\n",
        "        initial_budget = e.budget\n",
        "        # Double budget until exhaustive\n",
        "        while not _is_exhaustive(e, W):\n",
        "            if e.budget > 1e6: break\n",
        "            b_low = e.budget\n",
        "            e.budget *= 2\n",
        "            res_nxt = _mes_internal(e, real_budget=initial_budget)\n",
        "            if res_nxt is None: break\n",
        "            _, W = res_nxt\n",
        "            \n",
        "        # Binary search between low and high\n",
        "        b_high = e.budget\n",
        "        while not _is_exhaustive(e, W) and b_high - b_low >= 1:\n",
        "            e.budget = (b_high + b_low) / 2.0\n",
        "            res_med = _mes_internal(e, real_budget=initial_budget)\n",
        "            if res_med is None:\n",
        "                b_high = e.budget\n",
        "            else:\n",
        "                b_low = e.budget\n",
        "                _, W = res_med\n",
        "        e.budget = initial_budget\n",
        "        return W\n",
        "\n",
        "    if completion == 'utilitarian_greedy':\n",
        "        return _utilitarian_greedy_internal(e, W)\n",
        "\n",
        "    if completion == 'add1':\n",
        "        initial_budget = e.budget\n",
        "        while not _is_exhaustive(e, W):\n",
        "            if e.budget > 1e6: break\n",
        "            e.budget *= 1.01\n",
        "            res_nxt = _mes_internal(e, real_budget=initial_budget)\n",
        "            if res_nxt is None: break\n",
        "            _, W = res_nxt\n",
        "        e.budget = initial_budget\n",
        "        return W\n",
        "    \n",
        "    if completion == 'add1_utilitarian':\n",
        "        initial_budget = e.budget\n",
        "        while not _is_exhaustive(e, W):\n",
        "            if e.budget > 1e6: break\n",
        "            e.budget *= 1.01\n",
        "            res_nxt = _mes_internal(e, real_budget=initial_budget)\n",
        "            if res_nxt is None: break\n",
        "            _, W = res_nxt\n",
        "        e.budget = initial_budget\n",
        "        return _utilitarian_greedy_internal(e, W)\n",
        "\n",
        "    assert False, f\"Invalid value of parameter completion: {completion}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAaY5ODbDO0H"
      },
      "outputs": [],
      "source": [
        "def online_mes(utils: np.ndarray, k: int, seed: int = None, MEScompletion: str = None, exact_k: bool = True):\n",
        "    \"\"\"\n",
        "    Online Variant of the Method of Equal Shares.\n",
        "    Uses a sample phase (1/e of candidates) to estimate prices/budget, \n",
        "    then makes irrevocable decisions for the remaining stream.\n",
        "    \"\"\"\n",
        "    n, m = utils.shape\n",
        "    # Sample size threshold (1/e rule for secretary problems)\n",
        "    t = math.floor(m / math.e)\n",
        "\n",
        "    full_election = convert_input_to_election(utils, k)\n",
        "    all_candidates = list(full_election.profile.keys())\n",
        "    candidate_ids = list(range(len(all_candidates)))\n",
        "\n",
        "    if seed is not None:\n",
        "        rng = random.Random(seed)\n",
        "        rng.shuffle(candidate_ids)\n",
        "    else:\n",
        "        random.shuffle(candidate_ids)\n",
        "        \n",
        "    initial_ids = candidate_ids[:t]\n",
        "    remaining_ids = candidate_ids[t:]\n",
        "\n",
        "    # Run MES on the sample to establish reference\n",
        "    initial_profile = {\n",
        "        all_candidates[i]: full_election.profile[all_candidates[i]]\n",
        "        for i in initial_ids\n",
        "    }\n",
        "    initial_election = Election(voters=full_election.voters, budget=k)\n",
        "    initial_election.profile = initial_profile\n",
        "    initial_selection = equal_shares(initial_election, MEScompletion)\n",
        "\n",
        "    C_R = [all_candidates.index(c) for c in initial_selection]\n",
        "    C_R_r = C_R.copy()\n",
        "    selected = []\n",
        "\n",
        "    # Process the stream\n",
        "    for i, c_id in enumerate(remaining_ids):\n",
        "        remaining_count = len(remaining_ids) - i\n",
        "        \n",
        "        # Force selection if we are running out of candidates to fill k\n",
        "        if exact_k:\n",
        "            if len(selected) == k - remaining_count:\n",
        "                selected.extend(remaining_ids[i:])\n",
        "                break\n",
        "\n",
        "        candidate_set_ids = C_R_r + [c_id]\n",
        "        candidate_set = [all_candidates[i] for i in candidate_set_ids]\n",
        "        sub_profile = {c: full_election.profile[c] for c in candidate_set}\n",
        "\n",
        "        sub_election = Election(voters=full_election.voters, budget=k)\n",
        "        sub_election.profile = sub_profile\n",
        "        new_selection = equal_shares(sub_election, MEScompletion)\n",
        "        new_selection_ids = [all_candidates.index(c) for c in new_selection]\n",
        "\n",
        "        # If the current candidate is selected in the hypothetical offline run including history, select it\n",
        "        if c_id in new_selection_ids:\n",
        "            replaced = set(C_R_r) - set(new_selection_ids)\n",
        "            if any(r in C_R for r in replaced):\n",
        "                selected.append(c_id)\n",
        "\n",
        "        C_R_r = new_selection_ids\n",
        "\n",
        "    # Final fill if we didn't reach k (using sample or remaining)\n",
        "    if exact_k:\n",
        "        if len(selected) < k:\n",
        "            remaining_initial = [c for c in initial_ids if c not in selected]\n",
        "            needed = k - len(selected)\n",
        "            selected.extend(remaining_initial[:needed])\n",
        "\n",
        "            if len(selected) < k:\n",
        "                remaining_all = [c for c in candidate_ids if c not in selected]\n",
        "                needed = k - len(selected)\n",
        "                selected.extend(remaining_all[:needed])\n",
        "        return selected[:k]\n",
        "    return selected\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWENZrxbDpn6"
      },
      "outputs": [],
      "source": [
        "def bounded_overspending(e: Election, real_budget: int = 0) -> Set[Candidate]:\n",
        "    \"\"\"\n",
        "    Offline Bounded Overspending (BOS) implementation.\n",
        "    Calculates a 'ratio' for every candidate to determine eligibility.\n",
        "    \"\"\"\n",
        "    W = set()\n",
        "    costW = 0\n",
        "    remaining = set(c for c in e.profile)\n",
        "    endow = {i: 1.0 * safe_division(e.budget, len(e.voters)) for i in e.voters}\n",
        "    ratio = {c: -1.0 for c in e.profile}\n",
        "    \n",
        "    while True:\n",
        "        next_candidate = None\n",
        "        lowest_ratio = float(\"inf\")\n",
        "        remaining_sorted = sorted(remaining, key=lambda c: (ratio[c], c.id))\n",
        "        best_util = 0\n",
        "        \n",
        "        for c in remaining_sorted:\n",
        "            if ratio[c] >= lowest_ratio:\n",
        "                break\n",
        "            if costW + c.cost <= e.budget:\n",
        "                supporters_sorted = sorted([i for i in e.profile[c]], key=lambda i: safe_division(endow[i], e.profile[c][i]))\n",
        "                util = sum(e.profile[c].values())\n",
        "                money_used = 0\n",
        "                last_rho = 0\n",
        "                new_ratio = float(\"inf\")\n",
        "                \n",
        "                # Determine the specific ratio for this candidate\n",
        "                for i in supporters_sorted:\n",
        "                    denominator = e.profile[c][i]\n",
        "                    if denominator == 0 or not np.isfinite(denominator):\n",
        "                        continue \n",
        "\n",
        "                    numerator = endow[i]\n",
        "                    if not np.isfinite(numerator):\n",
        "                        continue\n",
        "\n",
        "                    util_safe = util if np.isfinite(util) else 0\n",
        "                    alpha = min(1.0, safe_division((money_used + util_safe * safe_division(numerator, denominator)), c.cost))\n",
        "                    \n",
        "                    if alpha > 1e-8:\n",
        "                        rho = safe_division(((alpha * c.cost) - money_used), (alpha * util))\n",
        "                        if rho < last_rho:\n",
        "                            break\n",
        "                        if rho / alpha < new_ratio :\n",
        "                            new_ratio = safe_division(rho, alpha)\n",
        "                            new_rho = rho\n",
        "                            \n",
        "                    util -= e.profile[c][i]\n",
        "                    money_used += endow[i]\n",
        "                    last_rho = safe_division(endow[i], e.profile[c][i])\n",
        "                \n",
        "                ratio[c] = new_ratio\n",
        "                if ratio[c] < lowest_ratio:\n",
        "                    lowest_ratio = ratio[c]\n",
        "                    lowest_rho = new_rho\n",
        "                    next_candidate = c\n",
        "                    best_util = sum([e.profile[c][i] for i in e.profile[c]])\n",
        "                elif ratio[c] == lowest_ratio:\n",
        "                    util = sum([e.profile[c][i] for i in e.profile[c]])\n",
        "                    if util > best_util:\n",
        "                        next_candidate = c\n",
        "                        best_util = util\n",
        "                        \n",
        "        if next_candidate is None:\n",
        "            break\n",
        "        else:\n",
        "            W.add(next_candidate)\n",
        "            costW += next_candidate.cost\n",
        "            remaining.remove(next_candidate)\n",
        "            for i in e.profile[next_candidate]:\n",
        "                endow[i] -= min(endow[i], lowest_rho * e.profile[next_candidate][i])\n",
        "            if real_budget: \n",
        "                if costW > real_budget:\n",
        "                    return None\n",
        "    return W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QP_uYXTWE1Hl"
      },
      "outputs": [],
      "source": [
        "def online_bos(utils: np.ndarray, k: int, seed: int = None, exact_k: bool = True):\n",
        "    \"\"\"\n",
        "    Online Variant of BOS (Bounded Overspending).\n",
        "    Uses the sample phase technique to establish initial ratios.\n",
        "    \"\"\"\n",
        "    n, m = utils.shape\n",
        "    t = math.floor(m / math.e)\n",
        "\n",
        "    full_election = convert_input_to_election(utils, k)\n",
        "    all_candidates = list(full_election.profile.keys())\n",
        "    candidate_ids = list(range(len(all_candidates)))\n",
        "\n",
        "    if seed is not None:\n",
        "        rng = random.Random(seed)\n",
        "        rng.shuffle(candidate_ids)\n",
        "    else:\n",
        "        random.shuffle(candidate_ids)\n",
        "        \n",
        "    initial_ids = candidate_ids[:t]\n",
        "    remaining_ids = candidate_ids[t:]\n",
        "    \n",
        "    initial_profile = {\n",
        "        all_candidates[i]: full_election.profile[all_candidates[i]]\n",
        "        for i in initial_ids\n",
        "    }\n",
        "    initial_election = Election(voters=full_election.voters, budget=k)\n",
        "    initial_election.profile = initial_profile\n",
        "    initial_selection = bounded_overspending(initial_election)\n",
        "    \n",
        "    C_R = [all_candidates.index(c) for c in initial_selection]\n",
        "    C_R_r = C_R.copy()\n",
        "    selected = []\n",
        "\n",
        "    for i, c_id in enumerate(remaining_ids):\n",
        "        remaining_count = len(remaining_ids) - i\n",
        "        if exact_k:\n",
        "            if len(selected) == k - remaining_count:\n",
        "                selected.extend(remaining_ids[i:])\n",
        "                break\n",
        "\n",
        "        candidate_set_ids = C_R_r + [c_id]\n",
        "        candidate_set = [all_candidates[i] for i in candidate_set_ids]\n",
        "        sub_profile = {c: full_election.profile[c] for c in candidate_set}\n",
        "\n",
        "        sub_election = Election(voters=full_election.voters, budget=k)\n",
        "        sub_election.profile = sub_profile\n",
        "        new_selection = bounded_overspending(sub_election)\n",
        "        new_selection_ids = [all_candidates.index(c) for c in new_selection]\n",
        "        \n",
        "        if c_id in new_selection_ids:\n",
        "            selected.append(c_id)\n",
        "\n",
        "        C_R_r = new_selection_ids\n",
        "        \n",
        "    if exact_k:\n",
        "        if len(selected) < k:\n",
        "            remaining_initial = [c for c in initial_ids if c not in selected]\n",
        "            selected.extend(remaining_initial[:k - len(selected)])\n",
        "\n",
        "            if len(selected) < k:\n",
        "                remaining_all = [c for c in candidate_ids if c not in selected]\n",
        "                selected.extend(remaining_all[:k - len(selected)])\n",
        "\n",
        "    return selected[:k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-FsHQonLWVf"
      },
      "outputs": [],
      "source": [
        "def utility_function_approval(voter, selected_projects, votes):\n",
        "    return sum(1 for project in votes[voter] if project in selected_projects)\n",
        "\n",
        "\n",
        "def utility_function_additive(voter, selected_projects, utilities, full_to_real_index):\n",
        "    total_utility = 0\n",
        "    voter_idx = int(voter)\n",
        "    voter_utilities = utilities[voter_idx]\n",
        "\n",
        "    for full_proj_idx in selected_projects:\n",
        "        real_proj_idx = full_to_real_index.get(full_proj_idx)\n",
        "        if real_proj_idx is None:\n",
        "            # dummy project, contributes 0\n",
        "            continue\n",
        "        total_utility += voter_utilities.get(real_proj_idx, 0)\n",
        "\n",
        "    return total_utility\n",
        "\n",
        "\n",
        "def utility_function(voter, selected_projects, votes, vote_type, full_to_real_index=None):\n",
        "    match vote_type:\n",
        "        case \"Approval\":\n",
        "            return utility_function_approval(voter, selected_projects, votes)\n",
        "        case \"Additive\":\n",
        "            if full_to_real_index is None:\n",
        "                raise ValueError(\"full_to_real_index must be provided for Additive vote type\")\n",
        "            return utility_function_additive(voter, selected_projects, votes, full_to_real_index)\n",
        "        case _:\n",
        "            logging.critical(\"Requested Vote Type is Not Supported!\")\n",
        "\n",
        "\n",
        "def social_welfare(selected_projects, voters, votes, vote_type, full_to_real_index=None):\n",
        "    return sum(math.log(1 + utility_function(voter, selected_projects, votes, vote_type, full_to_real_index)) for voter in voters)\n",
        "\n",
        "\n",
        "def is_dummy_project(project):\n",
        "    return isinstance(project, str) and project.startswith(\"__dummy__\")\n",
        "\n",
        "\n",
        "def insert_dummy_projects_randomly(projects, k, seed_dum=None):\n",
        "    \"\"\"Inserts dummy projects to ensure total candidates is a multiple of k.\"\"\"\n",
        "    n = len(projects)\n",
        "    remainder = n % k\n",
        "    if remainder == 0:\n",
        "        return projects\n",
        "\n",
        "    needed = k - remainder\n",
        "    dummy_projects = [f\"__dummy__{i}\" for i in range(needed)]\n",
        "\n",
        "    rng = random.Random(seed_dum)\n",
        "    insert_positions = sorted(rng.sample(range(n + 1), needed))\n",
        "\n",
        "    result = []\n",
        "    dummy_idx = 0\n",
        "    proj_idx = 0\n",
        "    for i in range(n + needed):\n",
        "        if dummy_idx < needed and i == insert_positions[dummy_idx] + dummy_idx:\n",
        "            result.append(dummy_projects[dummy_idx])\n",
        "            dummy_idx += 1\n",
        "        else:\n",
        "            result.append(projects[proj_idx])\n",
        "            proj_idx += 1\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def monotone_submodular_secretary(k, projects, voters, votes, vote_type, seed=None):\n",
        "    \"\"\"\n",
        "    Implementation of the Monotone Submodular Secretary algorithm (Online Nash).\n",
        "    Divides candidates into k phases and selects at most 1 per phase.\n",
        "    \"\"\"\n",
        "    real_projects = [p for p in projects if not is_dummy_project(p)]\n",
        "    indexed_real_projects = list(enumerate(real_projects))\n",
        "\n",
        "    if seed is not None:\n",
        "        rng = random.Random(seed)\n",
        "        rng.shuffle(indexed_real_projects)\n",
        "    else:\n",
        "        random.shuffle(indexed_real_projects)\n",
        "\n",
        "    shuffled_real_projects = [p for _, p in indexed_real_projects]\n",
        "\n",
        "    # Pad with dummy projects if necessary\n",
        "    if len(shuffled_real_projects) % k != 0:\n",
        "        projects_with_dummies = insert_dummy_projects_randomly(\n",
        "            shuffled_real_projects, k, seed_dum=(seed + 1 if seed is not None else None)\n",
        "        )\n",
        "    else:\n",
        "        projects_with_dummies = shuffled_real_projects\n",
        "\n",
        "    real_proj_mapping = {p: (idx, p) for idx, p in indexed_real_projects}\n",
        "\n",
        "    project_to_full_index = {}\n",
        "    for i, proj in enumerate(projects_with_dummies):\n",
        "        if not is_dummy_project(proj):\n",
        "            project_to_full_index[proj] = i\n",
        "\n",
        "    full_to_real_index = {}\n",
        "    for i, proj in enumerate(projects_with_dummies):\n",
        "        if is_dummy_project(proj):\n",
        "            full_to_real_index[i] = None\n",
        "        else:\n",
        "            full_to_real_index[i] = real_proj_mapping[proj][0]\n",
        "\n",
        "    final_indexed_projects = []\n",
        "    for proj in projects_with_dummies:\n",
        "        if is_dummy_project(proj):\n",
        "            final_indexed_projects.append((None, proj))\n",
        "        else:\n",
        "            final_indexed_projects.append(real_proj_mapping[proj])\n",
        "\n",
        "    selected_projects = []\n",
        "    elements_per_phase = len(final_indexed_projects) // k\n",
        "\n",
        "    # Phase-based selection\n",
        "    for phase in range(1, k + 1):\n",
        "        start_index = (phase - 1) * elements_per_phase\n",
        "        upper_index = start_index + int(elements_per_phase / math.e)\n",
        "        phase_end_index = phase * elements_per_phase\n",
        "\n",
        "        alpha = float(\"-inf\")\n",
        "\n",
        "        # Observation sub-phase (finding threshold alpha)\n",
        "        for index in range(start_index, min(upper_index, len(final_indexed_projects))):\n",
        "            _, project = final_indexed_projects[index]\n",
        "            candidate_set = [p for _, p in selected_projects] + [project]\n",
        "            alpha = max(alpha, social_welfare(candidate_set, voters, votes, vote_type, full_to_real_index))\n",
        "\n",
        "        current_value = social_welfare([p for _, p in selected_projects], voters, votes, vote_type, full_to_real_index)\n",
        "        alpha = max(alpha, current_value)\n",
        "\n",
        "        # Selection sub-phase\n",
        "        project_selected = None\n",
        "        for index in range(upper_index, min(phase_end_index, len(final_indexed_projects))):\n",
        "            idx, project = final_indexed_projects[index]\n",
        "            if is_dummy_project(project):\n",
        "                continue\n",
        "            candidate_set = [p for _, p in selected_projects] + [project]\n",
        "            value = social_welfare(candidate_set, voters, votes, vote_type, full_to_real_index)\n",
        "            if value >= alpha and project_selected is None:\n",
        "                project_selected = (idx, project)\n",
        "\n",
        "        # If nothing selected, force selection from the end of phase (if possible)\n",
        "        if project_selected is None:\n",
        "            for index in reversed(range(start_index, min(phase_end_index, len(final_indexed_projects)))):\n",
        "                idx, project = final_indexed_projects[index]\n",
        "                if not is_dummy_project(project):\n",
        "                    project_selected = (idx, project)\n",
        "                    break\n",
        "\n",
        "        if project_selected:\n",
        "            selected_projects.append(project_selected)\n",
        "\n",
        "    result_indices = []\n",
        "    for idx, proj in selected_projects:\n",
        "        if idx is not None:\n",
        "            full_idx = project_to_full_index[proj]\n",
        "            real_idx = full_to_real_index[full_idx]\n",
        "            if real_idx is not None:\n",
        "                result_indices.append(real_idx)\n",
        "    return result_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeTs-uzPUbBX"
      },
      "source": [
        "# Data Conversion and Functions for Comparison of Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YIReFPN5NvR"
      },
      "outputs": [],
      "source": [
        "def convert_pabulibdata(projects, votes, output_type):\n",
        "    \"\"\"Routes Pabulib data conversion based on algorithm requirement.\"\"\"\n",
        "    match output_type:\n",
        "        case \"SubmodularSecretary\":\n",
        "            project_list = list(projects.keys())\n",
        "            voter_list = list(votes.keys())\n",
        "            votes_by_voter = {voter: votes[voter]['vote'] for voter in voter_list}\n",
        "            return project_list, voter_list, votes_by_voter\n",
        "        case \"MES\" | \"Greedy\" | \"BOS\":\n",
        "            project_list = list(projects.keys())\n",
        "            voter_list = list(votes.keys())\n",
        "            votes_by_voter = {voter: votes[voter]['vote'] for voter in voter_list}\n",
        "            utilities = []\n",
        "            for voter_id in voter_list:\n",
        "                voter_utilities = [1 if project in votes_by_voter[voter_id] else 0 for project in project_list]\n",
        "                utilities.append(voter_utilities)\n",
        "            return np.array(utilities)\n",
        "        case _:\n",
        "            logging.critical(\"Requested Convert Type is Not Supported!\")\n",
        "\n",
        "def convert_matrix_utils(matrix_utils, output_type):\n",
        "    match output_type:\n",
        "        case \"SubmodularSecretary\":\n",
        "            n, m = len(matrix_utils), len(matrix_utils[0])\n",
        "            project_list = list(range(m))\n",
        "            voter_list = list(range(n))\n",
        "            votes_by_voter = [\n",
        "                {j: matrix_utils[i][j] for j in range(m) if matrix_utils[i][j] > 0}\n",
        "                for i in range(n)\n",
        "            ]\n",
        "            return project_list, voter_list, votes_by_voter\n",
        "        case \"MES\" | \"Greedy\" | \"BOS\":\n",
        "            return matrix_utils\n",
        "        case _:\n",
        "            logging.critical(\"Requested Convert Type is Not Supported!\")\n",
        "\n",
        "\n",
        "def read_csv_file(filepath):\n",
        "    \"\"\"Reads Pabulib format CSV files.\"\"\"\n",
        "    meta, projects, votes = {}, {}, {}\n",
        "    project_approval_count = {}\n",
        "\n",
        "    with open(filepath, 'r', newline='', encoding=\"utf-8\") as csvfile:\n",
        "        section = \"\"\n",
        "        reader = csv.reader(csvfile, delimiter=';')\n",
        "\n",
        "        for row in reader:\n",
        "            if row[0].strip().lower() in [\"meta\", \"projects\", \"votes\"]:\n",
        "                section = row[0].strip().lower()\n",
        "                header = next(reader)\n",
        "            elif section == \"meta\":\n",
        "                meta[row[0]] = row[1].strip()\n",
        "            elif section == \"projects\":\n",
        "                projects[row[0]] = {key.strip(): row[it + 1].strip() for it, key in enumerate(header[1:])}\n",
        "                project_approval_count[row[0]] = 0\n",
        "            elif section == \"votes\":\n",
        "                votes[row[0]] = {key.strip(): row[it + 1].strip() for it, key in enumerate(header[1:])}\n",
        "\n",
        "    for voter_data in votes.values():\n",
        "        for project in voter_data.get('vote', '').split(','):\n",
        "            project_approval_count[project] += 1\n",
        "\n",
        "    return meta, projects, votes, project_approval_count\n",
        "\n",
        "\n",
        "def convert_input_to_election(input_matrix: np.ndarray, k: int) -> Election:\n",
        "    voters = [Voter(str(i)) for i in range(input_matrix.shape[0])]\n",
        "    candidates = [Candidate(f\"c{i}\") for i in range(input_matrix.shape[1])]\n",
        "    election = Election(voters=set(voters), budget=k)\n",
        "    \n",
        "    profile = {}\n",
        "    for j in range(input_matrix.shape[1]):\n",
        "        candidate = candidates[j]\n",
        "        profile[candidate] = {}\n",
        "        for i in range(input_matrix.shape[0]):\n",
        "            profile[candidate][voters[i]] = input_matrix[i, j]\n",
        "\n",
        "    election.profile = profile\n",
        "    return election\n",
        "\n",
        "\n",
        "def average_satisfaction(utils, winners):\n",
        "    \"\"\"Calculate the average satisfaction of voters for a given winning committee.\"\"\"\n",
        "    n, m = utils.shape\n",
        "    if not isinstance(winners, list):\n",
        "        winners = list(winners)\n",
        "        \n",
        "    valid_winners = [w for w in winners if isinstance(w, int) and 0 <= w < m]\n",
        "    if not winners:\n",
        "        return 0\n",
        "\n",
        "    satisfaction = np.sum(utils[:, winners], axis=1)\n",
        "    all_satisfaction = satisfaction[satisfaction >= 0]\n",
        "    return np.mean(all_satisfaction)\n",
        "\n",
        "\n",
        "def exclusion_ratio(utils, winners):\n",
        "    \"\"\"Calculate the number of voters with zero satisfaction.\"\"\"\n",
        "    n, m = utils.shape\n",
        "    if not isinstance(winners, list):\n",
        "        winners = list(winners)\n",
        "        \n",
        "    satisfaction = np.sum(utils[:, winners], axis=1)\n",
        "    zero_satisfaction_count = np.sum(satisfaction == 0)\n",
        "    return zero_satisfaction_count\n",
        "\n",
        "\n",
        "def ejr_plus_violations(utils, winners, k, candidate_costs=None):\n",
        "    \"\"\"\n",
        "    Calculates EJR+ violations (for approval instances).\n",
        "    Returns: (count of violations, average shortfall)\n",
        "    \"\"\"\n",
        "    n, m = utils.shape\n",
        "    if candidate_costs is None:\n",
        "        candidate_costs = np.ones(m)\n",
        "\n",
        "    winners_set = set(winners)\n",
        "    satisfaction = np.sum(utils[:, list(winners_set)], axis=1)\n",
        "    sorted_voters = np.argsort(satisfaction)\n",
        "\n",
        "    violations = 0\n",
        "    total_shortfall = 0.0\n",
        "\n",
        "    for j in range(m):\n",
        "        if j in winners_set:\n",
        "            continue\n",
        "\n",
        "        supporters = np.where(utils[:, j] > 0)[0]\n",
        "        if len(supporters) == 0:\n",
        "            continue\n",
        "\n",
        "        threshold = (len(supporters) / n) * k\n",
        "\n",
        "        for i in sorted_voters:\n",
        "            if i in supporters:\n",
        "                if satisfaction[i] < threshold:\n",
        "                    violations += 1\n",
        "                    total_shortfall += (threshold - satisfaction[i])\n",
        "                    break\n",
        "\n",
        "    avg_shortfall = total_shortfall / violations if violations > 0 else 0.0\n",
        "    return violations, avg_shortfall\n",
        "\n",
        "\n",
        "def satisfaction_gini(utils, winners):\n",
        "    \"\"\"Compute the Gini coefficient of voter satisfaction.\"\"\"\n",
        "    if len(winners) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    satisfaction = np.sum(utils[:, winners], axis=1)\n",
        "    satisfaction_sorted = np.sort(satisfaction)\n",
        "    n = len(satisfaction_sorted)\n",
        "    index = np.arange(1, n + 1)\n",
        "\n",
        "    total = np.sum(satisfaction_sorted)\n",
        "    if total == 0:\n",
        "        return 0.0\n",
        "\n",
        "    gini = np.sum((2 * index - n - 1) * satisfaction_sorted) / (n * total)\n",
        "    return gini\n",
        "\n",
        "\n",
        "def percentile_utility(utils, winners, percentile=25):\n",
        "    satisfaction = np.sum(utils[:, winners], axis=1)\n",
        "    return np.percentile(satisfaction, percentile)\n",
        "\n",
        "\n",
        "def compare_algorithms(k_values, seeds, n, m, positive_fraction, max_utility, utils=None):\n",
        "    \"\"\"\n",
        "    Runs comparison suite for generated/provided utilities across multiple algorithms.\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    for k in k_values:\n",
        "        results[k] = {\n",
        "            alg: {\n",
        "                \"Avg Satisfaction\": [], \"Exclusion Ratio\": [], \"Gini\": [], \n",
        "                \"10th Percentile\": [], \"15th Percentile\": [], \"25th Percentile\": []\n",
        "            } for alg in [\"Greedy Budgeting\", \"Online MES\", \"Online BOS\", \"Offline MES\", \"Online Nash Rule\"]\n",
        "        }\n",
        "\n",
        "        for seed in seeds:\n",
        "            if utils is None:\n",
        "                utils = create_random_utilities(n, m, positive_fraction, max_utility, seed)\n",
        "\n",
        "            election = convert_input_to_election(utils, k)\n",
        "\n",
        "            # Offline MES\n",
        "            result_offline_mes_temp = equal_shares(election, completion='utilitarian_greedy')\n",
        "            result_offline_mes = sorted([int(''.join(filter(str.isdigit, str(c)))) for c in result_offline_mes_temp])\n",
        "\n",
        "            # Online Algorithms\n",
        "            selected_greedy = greedy(utils, k, seed)\n",
        "            selected_online_mes_greedycompletion = online_mes(utils, k, seed, 'utilitarian_greedy')\n",
        "            selected_online_bos = online_bos(utils, k, seed)\n",
        "\n",
        "            # Submodular Secretary\n",
        "            projects_list, voters_list, votes = convert_matrix_utils(utils, \"SubmodularSecretary\")\n",
        "            selected_submod = monotone_submodular_secretary(k, projects_list, voters_list, votes, \"Additive\", seed)\n",
        "\n",
        "            # Compute Metrics\n",
        "            for algo_name, selected in [\n",
        "                (\"Greedy Budgeting\", selected_greedy),\n",
        "                (\"Online BOS\", selected_online_bos),\n",
        "                (\"Online MES\", selected_online_mes_greedycompletion),\n",
        "                (\"Offline MES\", result_offline_mes),\n",
        "                (\"Online Nash Rule\", selected_submod)\n",
        "            ]:\n",
        "                avg_sat = average_satisfaction(utils, selected)\n",
        "                excl_ratio = exclusion_ratio(utils, selected)\n",
        "                gini = satisfaction_gini(utils, selected)\n",
        "                p10 = percentile_utility(utils, selected, percentile=10)\n",
        "                p15 = percentile_utility(utils, selected, percentile=15)\n",
        "                p25 = percentile_utility(utils, selected, percentile=25)\n",
        "\n",
        "                for metric, val in zip(\n",
        "                    [\"Avg Satisfaction\", \"Exclusion Ratio\", \"Gini\", \"10th Percentile\", \"15th Percentile\", \"25th Percentile\"],\n",
        "                    [avg_sat, excl_ratio, gini, p10, p15, p25]\n",
        "                ):\n",
        "                    results[k][algo_name][metric].append(val)\n",
        "    return results\n",
        "\n",
        "# Visual configurations\n",
        "color_marker = {\n",
        "    \"Online BOS\": (\"#2ca02c\", \"o\"),\n",
        "    \"Offline MES\": (\"#000000\", \"x\"),\n",
        "    \"Greedy Budgeting\": (\"#1f77b4\", \"s\"),\n",
        "    \"Online MES\": (\"#ff7f0e\", \"^\"),\n",
        "    \"Online Nash Rule\": (\"#d62728\", \"+\")\n",
        "}\n",
        "\n",
        "def plot_metric(metric):\n",
        "    \"\"\"Generates absolute metric plots.\"\"\"\n",
        "    output_dir = \"./plots\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    plt.rcParams.update({\n",
        "        'font.family': 'Times New Roman',\n",
        "        'axes.titlesize': 20,\n",
        "        'axes.labelsize': 18,\n",
        "        'xtick.labelsize': 16,\n",
        "        'ytick.labelsize': 16,\n",
        "        'legend.fontsize': 16,\n",
        "    })\n",
        "\n",
        "    var_labels = {\n",
        "        \"n\": \"Number of Voters\",\n",
        "        \"m\": \"Number of Candidates\",\n",
        "        \"k\": \"Committee Size\",\n",
        "        \"p\": \"Approval Probability\"\n",
        "    }\n",
        "\n",
        "    for var in [\"n\", \"m\", \"k\", \"p\"]:\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.title(f\"{metric} vs {var_labels[var]}\")\n",
        "\n",
        "        for alg in color_marker:\n",
        "            color, marker = color_marker[alg]\n",
        "            clean_label = alg.replace(\" with utilitarian completion\", \"\")\n",
        "            x_vals = sorted(set(entry[var] for entry in all_results))\n",
        "            y_vals, y_errs = [], []\n",
        "\n",
        "            for v in x_vals:\n",
        "                entries = [entry for entry in all_results if entry[var] == v and entry[\"algorithm\"] == alg]\n",
        "                if not entries:\n",
        "                    continue\n",
        "                y = np.mean([entry[metric] for entry in entries])\n",
        "                err = np.mean([entry[metric + \" std\"] for entry in entries])\n",
        "                y_vals.append(y)\n",
        "                y_errs.append(err)\n",
        "\n",
        "            if y_vals:\n",
        "                plt.errorbar(x_vals, y_vals, yerr=y_errs, label=clean_label,\n",
        "                             color=color, marker=marker, linestyle='-')\n",
        "\n",
        "        plt.xlabel(var_labels[var])\n",
        "        plt.ylabel(metric)\n",
        "        plt.grid(True)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        # Save logic\n",
        "        check_save = True\n",
        "        check_save_counter = 0\n",
        "        while check_save:\n",
        "            plot_filename = f\"{output_dir}/{metric.replace(' ', '_')}_vs_{var}_{check_save_counter}.png\"\n",
        "            check_save_counter += 1\n",
        "            if not os.path.exists(plot_filename):\n",
        "                plt.savefig(plot_filename)\n",
        "                check_save = False\n",
        "                break\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "def plot_relative_to_mes(metric):\n",
        "    \"\"\"Generates plots showing difference relative to Offline MES.\"\"\"\n",
        "    output_dir = \"./plots\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    var_labels = {\n",
        "        \"n\": \"Number of Voters\",\n",
        "        \"m\": \"Number of Candidates\",\n",
        "        \"k\": \"Committee Size\",\n",
        "        \"p\": \"Approval Probability\"\n",
        "    }\n",
        "\n",
        "    for var in [\"n\", \"k\", \"m\", \"p\"]:\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.title(f\"Absolute Relative Difference to Offline MES: {metric} vs {var_labels[var]}\")\n",
        "        x_vals = sorted(set(entry[var] for entry in all_results))\n",
        "\n",
        "        for alg in color_marker:\n",
        "            if alg == \"Offline MES\": continue\n",
        "            color, marker = color_marker[alg]\n",
        "            clean_label = alg.replace(\" with utilitarian completion\", \"\")\n",
        "            rel_diffs, filtered_x = [], []\n",
        "\n",
        "            for v in x_vals:\n",
        "                entries_alg = [entry for entry in all_results if entry[var] == v and entry[\"algorithm\"] == alg]\n",
        "                entries_mes = [entry for entry in all_results if entry[var] == v and entry[\"algorithm\"] == \"Offline MES\"]\n",
        "                if not entries_alg or not entries_mes: continue\n",
        "\n",
        "                y_alg = np.mean([entry[metric] for entry in entries_alg])\n",
        "                y_mes = np.mean([entry[metric] for entry in entries_mes])\n",
        "\n",
        "                if y_mes == 0:\n",
        "                    rel_diff = abs(y_alg - y_mes)\n",
        "                else:\n",
        "                    rel_diff = abs(y_alg - y_mes) / y_mes\n",
        "\n",
        "                rel_diffs.append(rel_diff)\n",
        "                filtered_x.append(v)\n",
        "\n",
        "            if rel_diffs:\n",
        "                plt.plot(filtered_x, rel_diffs, label=clean_label, color=color, marker=marker, linestyle='-')\n",
        "\n",
        "        plt.xlabel(var_labels[var])\n",
        "        plt.ylabel(\"Abs. Relative Difference\")\n",
        "        plt.grid(True)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOUOoVowVrTN"
      },
      "source": [
        "# Experiment 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36zS1nXVvG-W"
      },
      "outputs": [],
      "source": [
        "def classify_file(m):\n",
        "    if m < 10: return 'Small'\n",
        "    elif m >= 30: return 'Large'\n",
        "    else: return 'Medium'\n",
        "\n",
        "def run_experiment_one():\n",
        "    \"\"\"Reads Pabulib data and plots EJR+ violations.\"\"\"\n",
        "    data_dir = \"sample_data/PabulibData\"\n",
        "    seeds = list(range(1, 6))\n",
        "    num_runs = 1\n",
        "    rule_names = ['Greedy Budgeting', 'Online MES', 'Online BOS', 'Online Nash Rule']\n",
        "    \n",
        "    violations_data = defaultdict(lambda: defaultdict(list))\n",
        "    shortfall_data = defaultdict(lambda: defaultdict(list))\n",
        "    grouped_violations = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
        "    \n",
        "    file_number_counter = -1\n",
        "    fractions = [20, 15, 10, 7, 4, 2]\n",
        "    \n",
        "    for filepath in Path(data_dir).iterdir():\n",
        "        if filepath.is_file():\n",
        "            file_number_counter += 1\n",
        "            if file_number_counter % 50 == 0:\n",
        "                logging.info(f\"Processing File: {filepath.stem}\")\n",
        "            \n",
        "            try:\n",
        "                meta, projects, votes, _ = read_csv_file(filepath)\n",
        "                m = len(projects)\n",
        "                size_class = classify_file(m)\n",
        "                \n",
        "                project_list, voter_list, votes_by_voter = convert_pabulibdata(projects, votes, \"SubmodularSecretary\")\n",
        "                utils = convert_pabulibdata(projects, votes, \"Greedy\")\n",
        "\n",
        "                for fraction in fractions:\n",
        "                    m_fraction = m // fraction\n",
        "                    if m_fraction <= 0: continue\n",
        "\n",
        "                    for seed in seeds:\n",
        "                        for run in range(num_runs):\n",
        "                            selected = {}\n",
        "                            # Run Algorithms\n",
        "                            selected['Greedy Budgeting'] = greedy(utils, m_fraction, seed + run)\n",
        "                            selected['Online MES'] = online_mes(utils, m_fraction, seed + run, 'utilitarian_greedy')\n",
        "                            selected['Online BOS'] = online_bos(utils, m_fraction, seed + run)\n",
        "                            selected['Online Nash Rule'] = monotone_submodular_secretary(\n",
        "                                m_fraction, projects=project_list, voters=voter_list,\n",
        "                                votes=votes_by_voter, vote_type=\"Approval\", seed=seed + run\n",
        "                            )\n",
        "\n",
        "                            # Check Violations\n",
        "                            for rule in rule_names:\n",
        "                                winners = [int(w) for w in selected[rule] if int(w) < m]\n",
        "                                raw_violations, avg_shortfall = ejr_plus_violations(utils, winners, m_fraction)\n",
        "                                ratio_violations = raw_violations / len(votes)\n",
        "                                violations_data[fraction][rule].append(ratio_violations)\n",
        "                                shortfall_data[fraction][rule].append(avg_shortfall)\n",
        "                                grouped_violations[size_class][fraction][rule].append(ratio_violations)\n",
        "                                grouped_violations[\"All\"][fraction][rule].append(ratio_violations)\n",
        "\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error loading file {filepath.name}: {e}\")\n",
        "\n",
        "    # === Plot: Bar chart ===\n",
        "    all_fractions = sorted(set(violations_data.keys()), reverse=True)\n",
        "    fig, ax = plt.subplots(figsize=(14, 7))\n",
        "    bar_width = 0.15\n",
        "    x = np.arange(len(all_fractions))\n",
        "    colors = {\n",
        "        'Greedy Budgeting': '#1f77b4',\n",
        "        'Online MES': '#ff7f0e',\n",
        "        'Online BOS': '#2ca02c',\n",
        "        'Online Nash Rule': '#d62728'\n",
        "    }\n",
        "\n",
        "    for i, rule in enumerate(rule_names):\n",
        "        avg_heights = [np.mean(violations_data[fraction][rule]) if violations_data[fraction][rule] else 0 for fraction in all_fractions]\n",
        "        max_heights = [np.max(violations_data[fraction][rule]) if violations_data[fraction][rule] else 0 for fraction in all_fractions]\n",
        "        positions = x + (i - len(rule_names) / 2) * bar_width + bar_width / 2\n",
        "        ax.bar(positions, avg_heights, width=bar_width, label=f\"{rule} (avg)\", color=colors[rule], alpha=0.7)\n",
        "        diff = [max_h - avg_h if max_h > avg_h else 0 for max_h, avg_h in zip(max_heights, avg_heights)]\n",
        "        ax.bar(positions, diff, width=bar_width, bottom=avg_heights, label=f\"{rule} (max)\", color=colors[rule], alpha=0.3, hatch='//')\n",
        "\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels([f'm/{fraction}' for fraction in all_fractions])\n",
        "    ax.set_ylabel(\"EJR+ Violations (Voter Proportion in 01 Scale)\")\n",
        "    ax.set_title(\"Average and Max EJR+ Violations by Rule and Committee Size\")\n",
        "    ax.legend(loc='upper right', fontsize='small')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # === Tables: Average, Max, and Confidence Intervals ===\n",
        "    def build_violation_table(stat_fn=np.mean):\n",
        "        df = pd.DataFrame(index=[\"Small\", \"Medium\", \"Large\", \"All\"])\n",
        "        for rule in rule_names:\n",
        "            for fraction in fractions:\n",
        "                col_name = f\"{rule} m/{fraction}\"\n",
        "                for size_class in df.index:\n",
        "                    values = grouped_violations[size_class][fraction][rule]\n",
        "                    df.loc[size_class, col_name] = stat_fn(values) if values else 0\n",
        "        return df.astype(float)\n",
        "\n",
        "    def build_shortfall_table(stat_fn=np.mean):\n",
        "        df = pd.DataFrame(index=[\"Small\", \"Medium\", \"Large\", \"All\"])\n",
        "        for rule in rule_names:\n",
        "            for fraction in fractions:\n",
        "                col_name = f\"{rule} m/{fraction}\"\n",
        "                for size_class in df.index:\n",
        "                    values = grouped_shortfall[size_class][fraction][rule]\n",
        "                    df.loc[size_class, col_name] = stat_fn(values) if values else 0\n",
        "        return df.astype(float)\n",
        "\n",
        "    def build_confidence_interval_table():\n",
        "        df = pd.DataFrame(index=[\"Small\", \"Medium\", \"Large\", \"All\"])\n",
        "        for rule in rule_names:\n",
        "            for fraction in fractions:\n",
        "                col_name = f\"{rule} m/{fraction}\"\n",
        "                for size_class in df.index:\n",
        "                    values = grouped_violations[size_class][fraction][rule]\n",
        "\n",
        "                    # Clean up: remove NaN/inf and convert to numpy array\n",
        "                    clean_values = np.array(values)\n",
        "                    clean_values = clean_values[~np.isnan(clean_values)]\n",
        "                    clean_values = clean_values[np.isfinite(clean_values)]\n",
        "\n",
        "                    if len(clean_values) > 1:\n",
        "                        mean = np.mean(clean_values)\n",
        "                        sem = stats.sem(clean_values)\n",
        "\n",
        "                        if np.isfinite(sem) and sem > 0:\n",
        "                            ci = stats.t.interval(0.95, len(clean_values)-1, loc=mean, scale=sem)\n",
        "                            df.loc[size_class, col_name] = f\"[{ci[0]:.3f}, {ci[1]:.3f}]\"\n",
        "                        else:\n",
        "                            df.loc[size_class, col_name] = \"N/A\"\n",
        "                    else:\n",
        "                        df.loc[size_class, col_name] = \"N/A\"\n",
        "        return df\n",
        "\n",
        "    avg_violations_df = build_violation_table(np.mean)\n",
        "    max_violations_df = build_violation_table(np.max)\n",
        "    avg_shortfall_df = build_shortfall_table(np.mean)\n",
        "    ci_df = build_confidence_interval_table()\n",
        "\n",
        "    def plot_violation_tables_split(df, title_prefix):\n",
        "        fig, axes = plt.subplots(1, 5, figsize=(24, 4), constrained_layout=True)\n",
        "\n",
        "        for i, (rule, color) in enumerate(colors.items()):\n",
        "            cols = [col for col in df.columns if col.startswith(rule)]\n",
        "            sub_df = df[cols]\n",
        "\n",
        "            sns.heatmap(\n",
        "                sub_df,\n",
        "                annot=True,\n",
        "                fmt=\".4f\",\n",
        "                cmap=sns.light_palette(color, as_cmap=True),\n",
        "                linewidths=0.5,\n",
        "                cbar=False,\n",
        "                ax=axes[i]\n",
        "            )\n",
        "\n",
        "            axes[i].set_title(rule, fontsize=12, color=color)\n",
        "            axes[i].set_xlabel(\"Committee Size\")\n",
        "            axes[i].set_ylabel(\"File Size Category\")\n",
        "            axes[i].tick_params(axis='x', labelrotation=45)\n",
        "            axes[i].set_yticklabels(sub_df.index, rotation=0, fontsize=10)\n",
        "\n",
        "        fig.suptitle(f\"{title_prefix} EJR+ Violations by Rule and Committee Size\", fontsize=16)\n",
        "        plt.show()\n",
        "\n",
        "    def plot_ci_tables_split(df, title_prefix):\n",
        "        fig, axes = plt.subplots(1, 5, figsize=(32, 4), constrained_layout=True)\n",
        "\n",
        "        for i, (rule, color) in enumerate(colors.items()):\n",
        "            cols = [col for col in df.columns if col.startswith(rule)]\n",
        "            sub_df = df[cols]\n",
        "\n",
        "            # Create a simple table visualization for CI\n",
        "            for row_idx, (row_name, row_data) in enumerate(sub_df.iterrows()):\n",
        "                for col_idx, value in enumerate(row_data):\n",
        "                    axes[i].text(col_idx + 0.5, len(sub_df) - row_idx - 0.5, str(value),\n",
        "                               ha='center', va='center', fontsize=8)\n",
        "\n",
        "            axes[i].set_xlim(0, len(cols))\n",
        "            axes[i].set_ylim(0, len(sub_df))\n",
        "            axes[i].set_xticks(range(len(cols)))\n",
        "            axes[i].set_xticklabels([col.split(' ', 1)[1] for col in cols], rotation=45)\n",
        "            axes[i].set_yticks(range(len(sub_df)))\n",
        "            axes[i].set_yticklabels(reversed(sub_df.index))\n",
        "            axes[i].set_title(rule, fontsize=12, color=color)\n",
        "            axes[i].set_xlabel(\"Committee Size\")\n",
        "            axes[i].set_ylabel(\"File Size Category\")\n",
        "            axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "        fig.suptitle(f\"{title_prefix} 95% Confidence Intervals by Rule and Committee Size\", fontsize=16)\n",
        "        plt.show()\n",
        "\n",
        "    plot_violation_tables_split(avg_violations_df, \"Average\")\n",
        "    plot_violation_tables_split(max_violations_df, \"Max\")\n",
        "    plot_violation_tables_split(avg_shortfall_df, \"Average Shortfall\")\n",
        "    plot_ci_tables_split(ci_df, \"Violations\")\n",
        "\n",
        "    # Print average run time for each algorithm\n",
        "    logging.info(f\"\\n{Fore.YELLOW}=== Average running times ==={Style.RESET_ALL}\")\n",
        "    for algo, data in timing_data.items():\n",
        "        avg_time = data[\"total_time\"] / data[\"count\"]\n",
        "        logging.info(f\"{Fore.LIGHTYELLOW_EX}{algo}: {Fore.WHITE}{avg_time:.4f} seconds{Style.RESET_ALL}\")\n",
        "\n",
        "    logging.info(f\"\\n{Fore.YELLOW}=== File Counts by Size Category ==={Style.RESET_ALL}\")\n",
        "    for size_class in [\"Small\", \"Medium\", \"Large\", \"All\"]:\n",
        "        logging.info(f\"{Fore.LIGHTYELLOW_EX}{size_class}: {Fore.WHITE}{file_size_counter[size_class]} files {Style.RESET_ALL}\")\n",
        "        for pair in file_metadata[size_class]:\n",
        "            logging.info(f\"{Fore.BLACK}   (m={pair[0]}, n={pair[1]}){Style.RESET_ALL}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByJEbMfoW-V1"
      },
      "source": [
        "# Experiment 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GTOv7gPXBeK"
      },
      "outputs": [],
      "source": [
        "def parse_toi_file(path, max_utility=5, num_candidates=100):\n",
        "    \"\"\"\n",
        "    Parses .toi formatted preference files, preserving ties.\n",
        "    \n",
        "    In .toi files, braces {a, b} indicate that candidates a and b are tied \n",
        "    at the same rank.\n",
        "    \"\"\"\n",
        "    with open(path, 'r') as f:\n",
        "        # Filter out empty lines and comments\n",
        "        data_lines = [line.strip() for line in f if line.strip() and not line.startswith('#')]\n",
        "    \n",
        "    utilities = np.zeros((len(data_lines), num_candidates), dtype=int)\n",
        "\n",
        "    for i, line in enumerate(data_lines):\n",
        "        # Remove the count at the start (e.g., \"1: {1,2},3\" -> \"{1,2},3\")\n",
        "        line_content = line.split(':', 1)[-1].strip()\n",
        "        \n",
        "        # --- Parse the line into ranked groups ---\n",
        "        ranked_groups = []\n",
        "        current_token = ''\n",
        "        in_braces = False\n",
        "        \n",
        "        for ch in line_content:\n",
        "            if ch == '{':\n",
        "                in_braces = True\n",
        "                current_token += ch\n",
        "            elif ch == '}':\n",
        "                in_braces = False\n",
        "                current_token += ch\n",
        "            elif ch == ',' and not in_braces:\n",
        "                ranked_groups.append(current_token.strip())\n",
        "                current_token = ''\n",
        "            else:\n",
        "                current_token += ch\n",
        "        if current_token:\n",
        "            ranked_groups.append(current_token.strip())\n",
        "\n",
        "        # --- Assign Utilities ---\n",
        "        current_utility = max_utility\n",
        "        for token in ranked_groups:\n",
        "            # Check if this token represents a tie (e.g., \"{1, 2}\")\n",
        "            if token.startswith('{') and token.endswith('}'):\n",
        "                # Clean braces and split\n",
        "                group_ids = [int(x) - 1 for x in token.strip('{}').split(',')]\n",
        "                for idx in group_ids:\n",
        "                    if 0 <= idx < num_candidates:\n",
        "                        utilities[i][idx] = current_utility\n",
        "            else:\n",
        "                # Single candidate\n",
        "                if token:\n",
        "                    idx = int(token) - 1\n",
        "                    if 0 <= idx < num_candidates:\n",
        "                        utilities[i][idx] = current_utility\n",
        "            \n",
        "            # Decrease utility only once per group (preserving ties)\n",
        "            current_utility -= 1\n",
        "\n",
        "    return utilities\n",
        "\n",
        "# --- Parse the csv file and convert to utility matrix ---\n",
        "def parse_ratings_file(path, dataset_name=None):\n",
        "    num_users = 1000 if dataset_name == \"100K_Dataset\" else 0\n",
        "    num_movies = 1700 if dataset_name == \"100K_Dataset\" else 0\n",
        "\n",
        "    utilities = np.zeros((num_users, num_movies), dtype=float)\n",
        "\n",
        "    def split_line(line, delimiter='\\t'):\n",
        "        return line.strip().split(delimiter)\n",
        "\n",
        "    with open(path, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue  # Skip empty lines\n",
        "\n",
        "            delimiter = '\\t' if dataset_name == \"100K_Dataset\" else None\n",
        "\n",
        "            if delimiter is None:\n",
        "                logging.warning(\"Invalid Dataset Name!\")\n",
        "                return None\n",
        "\n",
        "            userId_str, movieId_str, rating_str, timestamp = split_line(line, delimiter)\n",
        "\n",
        "            userId = int(userId_str) - 1\n",
        "            movieId = int(movieId_str) - 1\n",
        "            rating = float(rating_str)\n",
        "\n",
        "            utilities[userId][movieId] = rating\n",
        "\n",
        "    return utilities\n",
        "\n",
        "def average_satisfaction_sushi(utils, winners):\n",
        "    num_candidates = utils.shape[1]\n",
        "    valid_winners = [w for w in winners if 0 <= w < num_candidates]\n",
        "\n",
        "    if not valid_winners:\n",
        "        return 0.0\n",
        "\n",
        "    satisfaction = np.sum(utils[:, valid_winners], axis=1)\n",
        "    return np.mean(satisfaction)\n",
        "\n",
        "\n",
        "def exclusion_ratio_sushi(utils, winners):\n",
        "    num_candidates = utils.shape[1]\n",
        "    valid_winners = [w for w in winners if 0 <= w < num_candidates]\n",
        "\n",
        "    if not valid_winners:\n",
        "        return 1.0\n",
        "\n",
        "    covered = (utils[:, valid_winners] > 0).any(axis=1)\n",
        "    ratio = 1.0 - np.mean(covered)\n",
        "    return ratio\n",
        "\n",
        "\n",
        "def percentile_utility_sushi(utils, winners, percentile):\n",
        "    num_candidates = utils.shape[1]\n",
        "    valid_winners = [w for w in winners if 0 <= w < num_candidates]\n",
        "\n",
        "    if not valid_winners:\n",
        "        return 0.0\n",
        "\n",
        "    utils_of_winners = np.sum(utils[:, valid_winners], axis=1)\n",
        "    return np.percentile(utils_of_winners, percentile)\n",
        "\n",
        "def gini_coefficient_sushi(x):\n",
        "    x = np.array(x, dtype=np.float64)\n",
        "    if x.size == 0:\n",
        "        return float('nan')\n",
        "    if np.all(x == 0):\n",
        "        return 0.0\n",
        "    x = np.sort(x)\n",
        "    n = x.size\n",
        "    cumx = np.cumsum(x)\n",
        "    gini = (n + 1 - 2 * np.sum(cumx) / cumx[-1]) / n\n",
        "    return gini\n",
        "\n",
        "\n",
        "def compare_algorithms_on_metrics(data_file_path, k_values, seeds, data_type=None, dataset_name=None):\n",
        "    utils = (\n",
        "        parse_toi_file(data_file_path) if data_type == \"sushi\"\n",
        "        else parse_ratings_file(data_file_path, dataset_name) if data_type == \"movies\"\n",
        "        else None\n",
        "    )\n",
        "\n",
        "    if utils is None:\n",
        "        logging.warning(\"Invalid Data Type!\")\n",
        "        return\n",
        "\n",
        "    num_candidates = utils.shape[1]\n",
        "\n",
        "    project_list, voter_list, votes_by_voter = convert_matrix_utils(utils, \"SubmodularSecretary\")\n",
        "\n",
        "    alg_names = [\"Greedy Budgeting\", \"Online MES\", \"Online BOS\", \"Online Nash Rule\"]\n",
        "\n",
        "    best_counts = defaultdict(lambda: defaultdict(int))\n",
        "    top2_counts = defaultdict(lambda: defaultdict(int))\n",
        "    worst_counts = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    second_counts = defaultdict(lambda: defaultdict(int))\n",
        "    third_counts = defaultdict(lambda: defaultdict(int))\n",
        "    fourth_counts = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    best_counts_all = defaultdict(lambda: defaultdict(int))\n",
        "    top2_counts_all = defaultdict(lambda: defaultdict(int))\n",
        "    worst_counts_all = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    second_counts_all = defaultdict(lambda: defaultdict(int))\n",
        "    third_counts_all = defaultdict(lambda: defaultdict(int))\n",
        "    fourth_counts_all = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    total_runs_per_k = {k: 0 for k in k_values}\n",
        "    total_runs_all = 0\n",
        "\n",
        "    sum_metrics_all = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
        "    count_metrics_all = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
        "\n",
        "\n",
        "    for k in k_values:\n",
        "        readable_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
        "        logging.info(f\"{Fore.BLACK}Start time: {readable_time} -------> K Value = {k}{Style.RESET_ALL}\")\n",
        "\n",
        "        for seed in seeds:\n",
        "            total_runs_per_k[k] += 1\n",
        "            total_runs_all += 1\n",
        "\n",
        "            results = {}\n",
        "\n",
        "            try:\n",
        "                results[\"Greedy Budgeting\"] = greedy(utils, k, seed)\n",
        "                results[\"Online MES\"] = online_mes(utils, k, seed, 'utilitarian_greedy')\n",
        "                results[\"Online BOS\"] = online_bos(utils, k, seed)\n",
        "                results[\"Online Nash Rule\"] = monotone_submodular_secretary(\n",
        "                    k,\n",
        "                    projects=project_list,\n",
        "                    voters=voter_list,\n",
        "                    votes=votes_by_voter,\n",
        "                    vote_type=\"Additive\",\n",
        "                    seed=seed\n",
        "                )\n",
        "\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Algorithm run error for k={k}, seed={seed}: {e}\")\n",
        "                continue\n",
        "\n",
        "            metrics_per_alg = {\n",
        "                \"average_satisfaction\": {},\n",
        "                \"exclusion_ratio\": {},\n",
        "                \"percentile_10\": {},\n",
        "                \"percentile_15\": {},\n",
        "                \"percentile_25\": {},\n",
        "                \"gini_coefficient\": {}\n",
        "            }\n",
        "\n",
        "            for alg in alg_names:\n",
        "                winners = results[alg]\n",
        "\n",
        "\n",
        "                try:\n",
        "                    avg_sat = average_satisfaction_sushi(utils, winners)\n",
        "                    excl_ratio = exclusion_ratio_sushi(utils, winners)\n",
        "                    p10 = percentile_utility_sushi(utils, winners, 10)\n",
        "                    p15 = percentile_utility_sushi(utils, winners, 15)\n",
        "                    p25 = percentile_utility_sushi(utils, winners, 25)\n",
        "                    utils_of_winners = np.sum(utils[:, winners], axis=1)\n",
        "                    gini = gini_coefficient_sushi(utils_of_winners)\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"Metric calculation error for {alg}, k={k}, seed={seed}: {e}\")\n",
        "                    avg_sat = excl_ratio = p10 = p15 = p25 = gini = float('nan')\n",
        "\n",
        "                metrics_per_alg[\"average_satisfaction\"][alg] = avg_sat\n",
        "                metrics_per_alg[\"exclusion_ratio\"][alg] = excl_ratio\n",
        "                metrics_per_alg[\"percentile_10\"][alg] = p10\n",
        "                metrics_per_alg[\"percentile_15\"][alg] = p15\n",
        "                metrics_per_alg[\"percentile_25\"][alg] = p25\n",
        "                metrics_per_alg[\"gini_coefficient\"][alg] = gini\n",
        "\n",
        "                # === Added: accumulate sums for average reporting ===\n",
        "                for metric, value in [\n",
        "                    (\"average_satisfaction\", avg_sat),\n",
        "                    (\"exclusion_ratio\", excl_ratio),\n",
        "                    (\"percentile_10\", p10),\n",
        "                    (\"percentile_15\", p15),\n",
        "                    (\"percentile_25\", p25),\n",
        "                    (\"gini_coefficient\", gini),\n",
        "                ]:\n",
        "                    if not np.isnan(value):\n",
        "                        sum_metrics_all[metric][k][alg] += value\n",
        "                        count_metrics_all[metric][k][alg] += 1\n",
        "\n",
        "\n",
        "            for metric, values in metrics_per_alg.items():\n",
        "                higher_is_better = metric not in (\"exclusion_ratio\", \"gini_coefficient\")\n",
        "\n",
        "                sorted_algs = sorted(\n",
        "                    values.items(),\n",
        "                    key=lambda x: x[1],\n",
        "                    reverse=higher_is_better\n",
        "                )\n",
        "\n",
        "                ordered_algs = [alg for alg, val in sorted_algs if not np.isnan(val)]\n",
        "\n",
        "                if not ordered_algs:\n",
        "                    continue\n",
        "\n",
        "                best_alg = ordered_algs[0]\n",
        "                best_counts[metric][(k, best_alg)] += 1\n",
        "                best_counts_all[metric][best_alg] += 1\n",
        "\n",
        "                for top_alg in ordered_algs[:2]:\n",
        "                    top2_counts[metric][(k, top_alg)] += 1\n",
        "                    top2_counts_all[metric][top_alg] += 1\n",
        "\n",
        "                worst_alg = ordered_algs[-1]\n",
        "                worst_counts[metric][(k, worst_alg)] += 1\n",
        "                worst_counts_all[metric][worst_alg] += 1\n",
        "\n",
        "                if len(ordered_algs) > 1:\n",
        "                    second_alg = ordered_algs[1]\n",
        "                    second_counts[metric][(k, second_alg)] += 1\n",
        "                    second_counts_all[metric][second_alg] += 1\n",
        "\n",
        "                if len(ordered_algs) > 2:\n",
        "                    third_alg = ordered_algs[2]\n",
        "                    third_counts[metric][(k, third_alg)] += 1\n",
        "                    third_counts_all[metric][third_alg] += 1\n",
        "\n",
        "                if len(ordered_algs) > 3:\n",
        "                    fourth_alg = ordered_algs[3]\n",
        "                    fourth_counts[metric][(k, fourth_alg)] += 1\n",
        "                    fourth_counts_all[metric][fourth_alg] += 1\n",
        "\n",
        "    logging.info(f\"\\n{Fore.YELLOW}=== Overall Results based on size of k ==={Style.RESET_ALL}\\n\")\n",
        "    size_categories = {\n",
        "        \"Small k (2, 5, 8)\": [2, 5, 8],\n",
        "        \"Medium k (15, 20, 25)\": [15, 20, 25],\n",
        "        \"Large k (35, 40, 45)\": [35, 40, 45],\n",
        "    }\n",
        "    for category_name, k_list in size_categories.items():\n",
        "        logging.info(f\"{Fore.LIGHTYELLOW_EX}{category_name}{Style.RESET_ALL}\")\n",
        "        for metric in [\"average_satisfaction\", \"exclusion_ratio\", \"percentile_10\", \"percentile_15\", \"percentile_25\", \"gini_coefficient\"]:\n",
        "            logging.info(f\" Metric: {metric}\")\n",
        "            total_runs_category = sum(total_runs_per_k[k] for k in k_list if k in total_runs_per_k) or 1\n",
        "            for alg in alg_names:\n",
        "                best_sum = sum(best_counts[metric][(k, alg)] for k in k_list if (k, alg) in best_counts[metric])\n",
        "                second_sum = sum(second_counts[metric][(k, alg)] for k in k_list if (k, alg) in second_counts[metric])\n",
        "                third_sum = sum(third_counts[metric][(k, alg)] for k in k_list if (k, alg) in third_counts[metric])\n",
        "                fourth_sum = sum(fourth_counts[metric][(k, alg)] for k in k_list if (k, alg) in fourth_counts[metric])\n",
        "                top2_sum = sum(top2_counts[metric][(k, alg)] for k in k_list if (k, alg) in top2_counts[metric])\n",
        "                worst_sum = sum(worst_counts[metric][(k, alg)] for k in k_list if (k, alg) in worst_counts[metric])\n",
        "\n",
        "                best_pct = 100 * best_sum / total_runs_category\n",
        "                second_pct = 100 * second_sum / total_runs_category\n",
        "                third_pct = 100 * third_sum / total_runs_category\n",
        "                fourth_pct = 100 * fourth_sum / total_runs_category\n",
        "                top2_pct = 100 * top2_sum / total_runs_category\n",
        "                worst_pct = 100 * worst_sum / total_runs_category\n",
        "\n",
        "                logging.info(\n",
        "                    f\"  {alg:20s} {Fore.BLACK}Best:{Style.RESET_ALL} {best_pct:6.2f}%, {Fore.BLACK}2nd:{Style.RESET_ALL} {second_pct:6.2f}%, \"\n",
        "                    f\"{Fore.BLACK}3rd:{Style.RESET_ALL} {third_pct:6.2f}%, {Fore.BLACK}4th:{Style.RESET_ALL} {fourth_pct:6.2f}%, \"\n",
        "                    f\"{Fore.BLACK}Top2:{Style.RESET_ALL} {top2_pct:6.2f}%, {Fore.BLACK}Worst:{Style.RESET_ALL} {worst_pct:6.2f}%\"\n",
        "                )\n",
        "\n",
        "    logging.info(f\"\\n{Fore.YELLOW}=== Overall Results (all k combined) ==={Style.RESET_ALL}\\n\")\n",
        "    for metric in [\"average_satisfaction\", \"exclusion_ratio\", \"percentile_10\", \"percentile_15\", \"percentile_25\", \"gini_coefficient\"]:\n",
        "        logging.info(f\"{Fore.LIGHTYELLOW_EX}Metric: {metric}{Style.RESET_ALL}\")\n",
        "        denom = total_runs_all or 1\n",
        "        for alg in alg_names:\n",
        "            best_pct = 100 * best_counts_all[metric][alg] / denom\n",
        "            second_pct = 100 * second_counts_all[metric][alg] / denom\n",
        "            third_pct = 100 * third_counts_all[metric][alg] / denom\n",
        "            fourth_pct = 100 * fourth_counts_all[metric][alg] / denom\n",
        "            top2_pct = 100 * top2_counts_all[metric][alg] / denom\n",
        "            worst_pct = 100 * worst_counts_all[metric][alg] / denom\n",
        "            logging.info(\n",
        "                    f\"  {alg:20s} {Fore.BLACK}Best:{Style.RESET_ALL} {best_pct:6.2f}%, {Fore.BLACK}2nd:{Style.RESET_ALL} {second_pct:6.2f}%, \"\n",
        "                    f\"{Fore.BLACK}3rd:{Style.RESET_ALL} {third_pct:6.2f}%, {Fore.BLACK}4th:{Style.RESET_ALL} {fourth_pct:6.2f}%, \"\n",
        "                    f\"{Fore.BLACK}Top2:{Style.RESET_ALL} {top2_pct:6.2f}%, {Fore.BLACK}Worst:{Style.RESET_ALL} {worst_pct:6.2f}%\"\n",
        "                )\n",
        "\n",
        "    logging.info(f\"\\n{Fore.YELLOW}=== Average Metric Values per Algorithm by k Size Category ==={Style.RESET_ALL}\\n\")\n",
        "    for category_name, k_list in size_categories.items():\n",
        "        logging.info(f\"{Fore.LIGHTYELLOW_EX}{category_name}{Style.RESET_ALL}\")\n",
        "        for metric in [\"average_satisfaction\", \"exclusion_ratio\", \"percentile_10\", \"percentile_15\", \"percentile_25\", \"gini_coefficient\"]:\n",
        "            logging.info(f\" Metric: {metric}\")\n",
        "            for alg in alg_names:\n",
        "                total_val = 0.0\n",
        "                total_count = 0\n",
        "                for k in k_list:\n",
        "                    total_val += sum_metrics_all[metric][k][alg]\n",
        "                    total_count += count_metrics_all[metric][k][alg]\n",
        "                avg_val = total_val / total_count if total_count > 0 else float('nan')\n",
        "                logging.info(f\"  {alg:20s} {Fore.BLACK}Average Value:{Style.RESET_ALL} {avg_val:.4f}\")\n",
        "\n",
        "    logging.info(f\"\\n{Fore.YELLOW}=== Average Metric Values (all k combined) ==={Style.RESET_ALL}\\n\")\n",
        "    for metric in [\"average_satisfaction\", \"exclusion_ratio\", \"percentile_10\", \"percentile_15\", \"percentile_25\", \"gini_coefficient\"]:\n",
        "        logging.info(f\"{Fore.LIGHTYELLOW_EX}Metric: {metric}{Style.RESET_ALL}\")\n",
        "        for alg in alg_names:\n",
        "            total_val = 0.0\n",
        "            total_count = 0\n",
        "            for k in k_values:\n",
        "                total_val += sum_metrics_all[metric][k][alg]\n",
        "                total_count += count_metrics_all[metric][k][alg]\n",
        "            avg_val = total_val / total_count if total_count > 0 else float('nan')\n",
        "            logging.info(f\"  {alg:20s} {Fore.BLACK}Average Value:{Style.RESET_ALL} {avg_val:.4f}\")\n",
        "\n",
        "def run_experiment_two_A():\n",
        "    k_values = [2, 5, 8, 15, 20, 25, 35, 40, 45]\n",
        "    seeds = list(range(20))\n",
        "    toi_file_path = \"sample_data/Sushi.txt\"\n",
        "    compare_algorithms_on_metrics(toi_file_path, k_values, seeds, data_type='sushi', dataset_name=\"Sushi\")\n",
        "\n",
        "def run_experiment_two_B():\n",
        "    k_values = [2, 5, 8, 15, 20, 25, 35, 40, 45]\n",
        "    seeds = list(range(50))\n",
        "    data_file_path = \"sample_data/MoviesRatings100k.csv\"\n",
        "    compare_algorithms_on_metrics(data_file_path, k_values=k_values, seeds=seeds, data_type='movies', dataset_name=\"100K_Dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs-BnIrNXutj"
      },
      "source": [
        "# Experiment 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xMWIwdkVngm"
      },
      "outputs": [],
      "source": [
        "def create_random_utilities(n, m, positive_fraction, max_utility, seed=None):\n",
        "    \"\"\"Generates Impartial Culture utilities (Random Approval).\"\"\"\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "    utilities = np.zeros((n, m), dtype=int)\n",
        "    for i in range(n):\n",
        "        num_positive = np.random.binomial(m, positive_fraction)\n",
        "        if num_positive == 0: continue\n",
        "        positive_candidates = np.random.choice(m, num_positive, replace=False)\n",
        "        mean_utility = 0.75 * max_utility\n",
        "        std_dev = 0.7 * max_utility\n",
        "        utilities[i, positive_candidates] = np.clip(\n",
        "            np.random.normal(loc=mean_utility, scale=std_dev, size=num_positive).round(), \n",
        "            1, max_utility\n",
        "        ).astype(int)\n",
        "    return utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jpd48hlIxWva"
      },
      "source": [
        "### Part A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44VUcEayxWva"
      },
      "outputs": [],
      "source": [
        "def plot_metric_normalized_exp3_A(metric):\n",
        "    output_dir = \"./plots\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    plt.rcParams.update({\n",
        "        'font.family': 'Times New Roman',  # Set font to Times New Roman\n",
        "        'axes.titlesize': 20,     # Title font size\n",
        "        'axes.labelsize': 18,     # X and Y axis label size\n",
        "        'xtick.labelsize': 16,    # X-axis tick label size\n",
        "        'ytick.labelsize': 16,    # Y-axis tick label size\n",
        "        'legend.fontsize': 16,    # Legend font size\n",
        "    })\n",
        "\n",
        "    var_labels = {\n",
        "        \"n\": \"Number of Voters\",\n",
        "        \"m\": \"Number of Candidates\",\n",
        "        \"k\": \"Committee Size\",\n",
        "        \"p\": \"Approval Probability\"\n",
        "    }\n",
        "\n",
        "    for var in [\"n\", \"m\", \"k\", \"p\"]:\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.title(f\"{metric} normalized to Offline MES (varied by {var_labels[var]})\")\n",
        "\n",
        "        x_vals = sorted(set(entry[var] for entry in all_results))\n",
        "        offline_mes_baseline = {}\n",
        "\n",
        "        for v in x_vals:\n",
        "            entries = [entry for entry in all_results if entry[var] == v and entry[\"algorithm\"] == \"Offline MES\"]\n",
        "            if entries:\n",
        "                baseline_value = np.mean([entry[metric] for entry in entries])\n",
        "                offline_mes_baseline[v] = baseline_value\n",
        "\n",
        "        for alg in color_marker:\n",
        "            color, marker = color_marker[alg]\n",
        "            clean_label = alg.replace(\" with utilitarian completion\", \"\")\n",
        "            if clean_label == \"Greedy\":\n",
        "                clean_label = \"Greedy Budgeting\"\n",
        "\n",
        "            y_vals, y_errs, x_vals_filtered = [], [], []\n",
        "\n",
        "            for v in x_vals:\n",
        "                entries = [entry for entry in all_results if entry[var] == v and entry[\"algorithm\"] == alg]\n",
        "                if not entries or v not in offline_mes_baseline:\n",
        "                    continue\n",
        "\n",
        "                y = np.mean([entry[metric] for entry in entries])\n",
        "                err = np.mean([entry[metric + \" std\"] for entry in entries])\n",
        "                baseline = offline_mes_baseline[v]\n",
        "\n",
        "                if baseline > 0:\n",
        "                    normalized_y = y / baseline\n",
        "                    normalized_err = err / baseline\n",
        "                else:\n",
        "                    normalized_y = 0\n",
        "                    normalized_err = 0\n",
        "\n",
        "                y_vals.append(normalized_y)\n",
        "                y_errs.append(normalized_err)\n",
        "                x_vals_filtered.append(v)\n",
        "\n",
        "            if y_vals:\n",
        "                plt.errorbar(x_vals_filtered, y_vals, yerr=y_errs, label=clean_label,\n",
        "                             color=color, marker=marker, linestyle='-')\n",
        "\n",
        "        plt.xlabel(var_labels[var])\n",
        "        plt.ylabel(f\"{metric} (relative to Offline MES)\")\n",
        "        plt.grid(True)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save and show the plot\n",
        "        check_save = True\n",
        "        check_save_counter = 0\n",
        "        while check_save:\n",
        "            plot_filename = f\"{output_dir}/{metric.replace(' ', '_')}_normalized_{var}_{check_save_counter}.png\"\n",
        "            check_save_counter += 1\n",
        "\n",
        "            if not os.path.exists(plot_filename):\n",
        "                plt.savefig(plot_filename)\n",
        "                check_save = False\n",
        "                break\n",
        "\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "    return \"All plots generated and saved successfully.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvAYiigQM010"
      },
      "outputs": [],
      "source": [
        "# Experiment settings\n",
        "n_values = [5, 10, 20, 30, 50, 70, 100, 150]\n",
        "m_k_pairs = [\n",
        "    (10, 2), (10, 4),\n",
        "    (20, 2), (20, 4), (20, 5),\n",
        "    (30, 2), (30,4), (30, 5), (30, 10),\n",
        "    (50, 5), (50, 10), (50, 12), (50, 15),\n",
        "    (80, 10), (80, 12), (80, 15), (80, 20), (80, 30),\n",
        "    (100, 12), (100, 15), (100, 20), (100, 30),\n",
        "    (120, 15), (120, 20), (120,30), (120, 40),\n",
        "    (150, 20), (150, 30), (150, 40),\n",
        "    (200, 20), (200, 30), (200, 40)]\n",
        "\n",
        "p_values = [0.2, 0.4, 0.6, 0.8, 1]\n",
        "max_utility = 200\n",
        "seed_values = range(0,10)\n",
        "all_results = []\n",
        "\n",
        "def run_experiment_three_A():\n",
        "    for n in n_values:\n",
        "        # Monitor the state of the ongoing process\n",
        "        readable_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
        "        logging.info(f\"{Fore.BLACK}Start time: {readable_time} -------> N Value = {n}{Style.RESET_ALL}\")\n",
        "        for (m, k), p in itertools.product(m_k_pairs, p_values):\n",
        "            for seed in seed_values:\n",
        "                utils = create_random_utilities(n, m, p, max_utility, seed)\n",
        "\n",
        "                result = compare_algorithms([k], [seed], n, m, p, max_utility, utils)\n",
        "\n",
        "                for alg in result[k]:\n",
        "                    metrics = result[k][alg]\n",
        "                    all_results.append({\n",
        "                        \"n\": n, \"m\": m, \"k\": k, \"p\": p, \"seed\": seed, \"algorithm\": alg,\n",
        "                        \"Avg Satisfaction\": np.mean(metrics[\"Avg Satisfaction\"]),\n",
        "                        \"Avg Satisfaction std\": np.std(metrics[\"Avg Satisfaction\"]),\n",
        "                        \"Exclusion Ratio\": np.mean(metrics[\"Exclusion Ratio\"]),\n",
        "                        \"Exclusion Ratio std\": np.std(metrics[\"Exclusion Ratio\"]),\n",
        "                        \"Gini\": np.mean(metrics[\"Gini\"]),\n",
        "                        \"Gini std\": np.std(metrics[\"Gini\"]),\n",
        "                        \"10th Percentile\": np.mean(metrics[\"10th Percentile\"]),\n",
        "                        \"10th Percentile std\": np.std(metrics[\"10th Percentile\"]),\n",
        "                        \"15th Percentile\": np.mean(metrics[\"15th Percentile\"]),\n",
        "                        \"15th Percentile std\": np.std(metrics[\"15th Percentile\"]),\n",
        "                        \"25th Percentile\": np.mean(metrics[\"25th Percentile\"]),\n",
        "                        \"25th Percentile std\": np.std(metrics[\"25th Percentile\"]),\n",
        "                        \"m/k\": m / k,\n",
        "                        \"k/n\": k / n\n",
        "                    })\n",
        "\n",
        "\n",
        "    for metric in [\"Avg Satisfaction\", \"Exclusion Ratio\", \"Gini\", \"10th Percentile\", \"15th Percentile\", \"25th Percentile\"]:\n",
        "        plot_metric(metric)\n",
        "        plot_relative_to_mes(metric)\n",
        "        plot_metric_normalized_exp3_A(metric)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP-qtd5PxWva"
      },
      "source": [
        "### Part B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxld2WARxWvb"
      },
      "outputs": [],
      "source": [
        "def plot_metric_normalized_exp3_BandC(metric):\n",
        "    output_dir = \"./plots\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    plt.rcParams.update({\n",
        "        'font.family': 'Times New Roman',  # Set font to Times New Roman\n",
        "        'axes.titlesize': 20,     # Title font size\n",
        "        'axes.labelsize': 18,     # X and Y axis label size\n",
        "        'xtick.labelsize': 16,    # X-axis tick label size\n",
        "        'ytick.labelsize': 16,    # Y-axis tick label size\n",
        "        'legend.fontsize': 16,    # Legend font size\n",
        "    })\n",
        "\n",
        "    var_labels = {\n",
        "        \"n\": \"Number of Voters\",\n",
        "        \"m\": \"Number of Candidates\",\n",
        "        \"k\": \"Committee Size\",\n",
        "        \"phi\": \"Dispersion Parameter ()\"\n",
        "    }\n",
        "\n",
        "    for var in [\"n\", \"m\", \"k\", \"phi\"]:\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.title(f\"{metric} (Normalized to Offline MES) vs {var_labels[var]}\")\n",
        "\n",
        "        x_vals = sorted(set(entry[var] for entry in all_results))\n",
        "        offline_mes_baseline = {}\n",
        "\n",
        "        for v in x_vals:\n",
        "            entries = [entry for entry in all_results if entry[var] == v and entry[\"algorithm\"] == \"Offline MES\"]\n",
        "            if entries:\n",
        "                baseline_value = np.mean([entry[metric] for entry in entries])\n",
        "                offline_mes_baseline[v] = baseline_value\n",
        "\n",
        "        for alg in color_marker:\n",
        "            color, marker = color_marker[alg]\n",
        "            clean_label = alg.replace(\" with utilitarian completion\", \"\")\n",
        "            if clean_label == \"Greedy\":\n",
        "                clean_label = \"Greedy Budgeting\"\n",
        "\n",
        "            y_vals, y_errs, x_vals_filtered = [], [], []\n",
        "\n",
        "            for v in x_vals:\n",
        "                entries = [entry for entry in all_results if entry[var] == v and entry[\"algorithm\"] == alg]\n",
        "                if not entries or v not in offline_mes_baseline:\n",
        "                    continue\n",
        "\n",
        "                y = np.mean([entry[metric] for entry in entries])\n",
        "                err = np.mean([entry[metric + \" std\"] for entry in entries])\n",
        "\n",
        "                baseline = offline_mes_baseline[v]\n",
        "                if baseline > 0:  # Avoid division by zero\n",
        "                    normalized_y = y / baseline\n",
        "                    normalized_err = err / baseline\n",
        "                else:\n",
        "                    normalized_y = 0\n",
        "                    normalized_err = 0\n",
        "\n",
        "                y_vals.append(normalized_y)\n",
        "                y_errs.append(normalized_err)\n",
        "                x_vals_filtered.append(v)\n",
        "\n",
        "            if y_vals:\n",
        "                plt.errorbar(x_vals_filtered, y_vals, yerr=y_errs, label=clean_label,\n",
        "                             color=color, marker=marker, linestyle='-')\n",
        "\n",
        "        plt.xlabel(var_labels[var])\n",
        "        plt.ylabel(f\"{metric} (relative to Offline MES)\")\n",
        "        plt.grid(True)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save and show the plot\n",
        "        check_save = True\n",
        "        check_save_counter = 0\n",
        "        while check_save:\n",
        "            plot_filename = f\"{output_dir}/{metric.replace(' ', '_')}_normalized_vs_{var}_{check_save_counter}.png\"\n",
        "            check_save_counter += 1\n",
        "            if not os.path.exists(plot_filename):\n",
        "                plt.savefig(plot_filename)\n",
        "                check_save = False\n",
        "                break\n",
        "\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "    return \"All normalized plots saved in './plots'.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUBjZUxu_okq"
      },
      "outputs": [],
      "source": [
        "def sample_mallows_ranking(reference, phi):\n",
        "    \"\"\"Samples one ranking from the Mallows model using the insert-based method.\"\"\"\n",
        "    ranking = [reference[0]]\n",
        "    for i in range(1, len(reference)):\n",
        "        probs = [phi ** j for j in range(i + 1)]\n",
        "        probs = np.array(probs) / sum(probs)\n",
        "        insert_pos = np.random.choice(i + 1, p=probs)\n",
        "        ranking.insert(insert_pos, reference[i])\n",
        "    return ranking\n",
        "\n",
        "def create_mallows_utilities(n, m, phi=0.8, max_utility=10, min_utility=1,\n",
        "                            utility_noise=2, seed=None, return_rankings=False):\n",
        "\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "        random.seed(seed)\n",
        "\n",
        "    reference_ranking = list(range(m))\n",
        "    utilities = np.zeros((n, m), dtype=int)\n",
        "    rankings = []\n",
        "\n",
        "    for i in range(n):\n",
        "        ranking = sample_mallows_ranking(reference_ranking, phi)\n",
        "        rankings.append(ranking)\n",
        "\n",
        "\n",
        "        base_range = max_utility - min_utility\n",
        "        step = base_range / (m - 1) if m > 1 else base_range\n",
        "\n",
        "        base_utilities = np.zeros(m, dtype=int)\n",
        "        for j, candidate in enumerate(ranking):\n",
        "            base_utilities[candidate] = max(min_utility, int(max_utility - j * step))\n",
        "\n",
        "        for j in range(m):\n",
        "            candidate = ranking[j]\n",
        "\n",
        "            if j == 0:\n",
        "                if j + 1 < m:\n",
        "                    lower_bound = base_utilities[ranking[j+1]] + 1\n",
        "                else:\n",
        "                    lower_bound = min_utility\n",
        "                upper_bound = max_utility\n",
        "            elif j == m - 1:\n",
        "                lower_bound = min_utility\n",
        "                upper_bound = base_utilities[ranking[j-1]] - 1\n",
        "            else:\n",
        "                lower_bound = base_utilities[ranking[j+1]] + 1\n",
        "                upper_bound = base_utilities[ranking[j-1]] - 1\n",
        "\n",
        "            # Apply noise within safe bounds\n",
        "            noise_range = min(utility_noise, (upper_bound - lower_bound) // 2)\n",
        "            if noise_range > 0:\n",
        "                noise = np.random.randint(-noise_range, noise_range + 1)\n",
        "                utilities[i, candidate] = max(lower_bound, min(upper_bound, base_utilities[candidate] + noise))\n",
        "            else:\n",
        "                utilities[i, candidate] = base_utilities[candidate]\n",
        "\n",
        "        for j in range(m-1):\n",
        "            if utilities[i, ranking[j]] <= utilities[i, ranking[j+1]]:\n",
        "                utilities[i, ranking[j]] = utilities[i, ranking[j+1]] + 1\n",
        "\n",
        "    if return_rankings:\n",
        "        return utilities, rankings\n",
        "    return utilities\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Wq0k5avxWvb"
      },
      "outputs": [],
      "source": [
        "def group_by_param_and_algorithm(results, param_name):\n",
        "    param_values = sorted(list(set(result[param_name] for result in results if param_name in result)))\n",
        "    alg_names = sorted(list(set(result[\"algorithm\"] for result in results)))\n",
        "\n",
        "    grouped_data = {\n",
        "        param_val: {alg: [] for alg in alg_names}\n",
        "        for param_val in param_values\n",
        "    }\n",
        "\n",
        "    for result in results:\n",
        "        param_val = result[param_name]\n",
        "        alg = result[\"algorithm\"]\n",
        "        grouped_data[param_val][alg].append(result)\n",
        "\n",
        "    return grouped_data, param_values, alg_names\n",
        "\n",
        "def plot_metric_by_param(metric, param_name, xlabel, results=None):\n",
        "\n",
        "\n",
        "    if results is None:\n",
        "        results = all_results\n",
        "\n",
        "    color_marker = {\n",
        "        \"Online BOS\": (\"#2ca02c\", \"o\"),\n",
        "        \"Offline MES\": (\"#000000\", \"x\"),\n",
        "        \"Greedy Budgeting\": (\"#1f77b4\", \"s\"),\n",
        "        \"Online MES\": (\"#ff7f0e\", \"^\"),\n",
        "        \"Online Nash Rule\": (\"#d62728\", \"+\")\n",
        "    }\n",
        "\n",
        "    param_labels = {\n",
        "        \"n\": \"Number of Voters\",\n",
        "        \"m\": \"Number of Candidates\",\n",
        "        \"k\": \"Committee Size\",\n",
        "        \"phi\": \"Dispersion Parameter ()\",\n",
        "        \"m/k\": \"Candidates per Committee Member (m/k)\",\n",
        "        \"k/n\": \"Committee Size as Fraction of Voters (k/n)\"\n",
        "    }\n",
        "\n",
        "    readable_xlabel = param_labels.get(param_name, xlabel)\n",
        "\n",
        "    filtered_results = [r for r in results if not np.isnan(r[metric])]\n",
        "\n",
        "    grouped_data, param_values, alg_names = group_by_param_and_algorithm(filtered_results, param_name)\n",
        "\n",
        "    plt.rcParams.update({\n",
        "        'font.family': 'Times New Roman',  # Set font to Times New Roman\n",
        "        'axes.titlesize': 20,     # Title font size\n",
        "        'axes.labelsize': 18,     # X and Y axis label size\n",
        "        'xtick.labelsize': 16,    # X-axis tick label size\n",
        "        'ytick.labelsize': 16,    # Y-axis tick label size\n",
        "        'legend.fontsize': 16,    # Legend font size\n",
        "    })\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    for alg in alg_names:\n",
        "        x_values = []\n",
        "        y_values = []\n",
        "        yerr_values = []\n",
        "\n",
        "        for param_val in param_values:\n",
        "            alg_results = grouped_data[param_val][alg]\n",
        "            if alg_results:\n",
        "                x_values.append(param_val)\n",
        "                y_values.append(np.mean([r[metric] for r in alg_results]))\n",
        "                yerr_values.append(np.std([r[metric] for r in alg_results]) / np.sqrt(len(alg_results)))\n",
        "\n",
        "        if x_values:\n",
        "            color, marker = color_marker.get(alg, (\"gray\", \"o\"))  # Fallback to gray if not found\n",
        "            plt.errorbar(x_values, y_values, yerr=yerr_values, label=alg,\n",
        "                         color=color, marker=marker, linestyle='-', capsize=5)\n",
        "\n",
        "    plt.xlabel(readable_xlabel)\n",
        "    plt.ylabel(metric)\n",
        "    plt.title(f\"{metric} vs {readable_xlabel}\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_metrics_against_parameters():\n",
        "    metrics = [\"Avg Satisfaction\", \"Exclusion Ratio\", \"Gini\", \"10th Percentile\", \"15th Percentile\", \"25th Percentile\"]\n",
        "\n",
        "    # Plot against n (number of voters)\n",
        "    for metric in metrics:\n",
        "        # Get results for each value of n, averaging over other parameters\n",
        "        plot_metric_by_param(metric, \"n\", \"Number of Voters (n)\", all_results)\n",
        "\n",
        "    # Plot against phi (dispersion parameter)\n",
        "    for metric in metrics:\n",
        "        plot_metric_by_param(metric, \"phi\", \"Dispersion Parameter (phi)\", all_results)\n",
        "\n",
        "    for metric in metrics:\n",
        "        plot_metric_normalized_exp3_BandC(metric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBoPJ4qO_1aP"
      },
      "outputs": [],
      "source": [
        "# Experiment settings\n",
        "n_values = [5, 10, 20, 30, 50, 70, 100, 150]\n",
        "m_k_pairs = [\n",
        "    (10, 2), (10, 4),\n",
        "    (20, 2), (20, 4), (20, 5),\n",
        "    (30, 2), (30,4), (30, 5), (30, 10),\n",
        "    (50, 5), (50, 10), (50, 12), (50, 15),\n",
        "    (80, 10), (80, 12), (80, 15), (80, 20), (80, 30),\n",
        "    (100, 12), (100, 15), (100, 20), (100, 30),\n",
        "    (120, 15), (120, 20), (120,30), (120, 40),\n",
        "    (150, 20), (150, 30), (150, 40),\n",
        "    (200, 20), (200, 30), (200, 40)]\n",
        "\n",
        "phi_values = [0.2, 0.4, 0.6, 0.8, 1]\n",
        "max_utility = 200\n",
        "min_utility = 0\n",
        "utility_noise = 50\n",
        "seed_values = range(0, 10)\n",
        "\n",
        "all_results = []\n",
        "\n",
        "def run_experiment_three_B():\n",
        "    for n in n_values:\n",
        "        # Monitor the state of the ongoing process\n",
        "        readable_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
        "        logging.info(f\"{Fore.BLACK}Start time: {readable_time} -------> N Value = {n}{Style.RESET_ALL}\")\n",
        "        for (m, k), phi in itertools.product(m_k_pairs, phi_values):\n",
        "            for seed in seed_values:\n",
        "                utils = create_mallows_utilities(n, m, phi=phi, max_utility=max_utility, min_utility=min_utility,\n",
        "                                                 utility_noise=utility_noise, seed=seed)\n",
        "\n",
        "                result = compare_algorithms([k], [seed], n, m, phi, max_utility, utils)\n",
        "\n",
        "\n",
        "                for alg in result[k]:\n",
        "                    metrics = result[k][alg]\n",
        "                    all_results.append({\n",
        "                        \"n\": n, \"m\": m, \"k\": k, \"phi\": phi, \"seed\": seed, \"algorithm\": alg,\n",
        "                        \"Avg Satisfaction\": np.mean(metrics[\"Avg Satisfaction\"]),\n",
        "                        \"Avg Satisfaction std\": np.std(metrics[\"Avg Satisfaction\"]),\n",
        "                        \"Exclusion Ratio\": np.mean(metrics[\"Exclusion Ratio\"]),\n",
        "                        \"Exclusion Ratio std\": np.std(metrics[\"Exclusion Ratio\"]),\n",
        "                        \"Gini\": np.mean(metrics[\"Gini\"]),\n",
        "                        \"Gini std\": np.std(metrics[\"Gini\"]),\n",
        "                        \"10th Percentile\": np.mean(metrics[\"10th Percentile\"]),\n",
        "                        \"10th Percentile std\": np.std(metrics[\"10th Percentile\"]),\n",
        "                        \"15th Percentile\": np.mean(metrics[\"15th Percentile\"]),\n",
        "                        \"15th Percentile std\": np.std(metrics[\"15th Percentile\"]),\n",
        "                        \"25th Percentile\": np.mean(metrics[\"25th Percentile\"]),\n",
        "                        \"25th Percentile std\": np.std(metrics[\"25th Percentile\"]),\n",
        "                        \"m/k\": m / k,\n",
        "                        \"k/n\": k / n\n",
        "                    })\n",
        "\n",
        "    # Generate all plots\n",
        "    plot_metrics_against_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc2byEQ9xWvb"
      },
      "source": [
        "### Part C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_SaoHd-xWvb"
      },
      "outputs": [],
      "source": [
        "def create_mallows_utilities_normalized(n, m, phi=0.8, max_utility=10, min_utility=1,\n",
        "                            utility_noise=2, seed=None):\n",
        "\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "        random.seed(seed)\n",
        "\n",
        "    # Generate rankings using prefsampling\n",
        "    rankings = norm_mallows(n, m, phi, seed=seed)\n",
        "\n",
        "\n",
        "    utilities = np.zeros((n, m), dtype=int)\n",
        "\n",
        "    for i in range(n):\n",
        "        ranking = rankings[i]\n",
        "\n",
        "\n",
        "        base_range = max_utility - min_utility\n",
        "        step = base_range / (m - 1) if m > 1 else base_range\n",
        "\n",
        "        base_utilities = np.zeros(m, dtype=int)\n",
        "        for j, candidate in enumerate(ranking):\n",
        "            base_utilities[candidate] = max(min_utility, int(max_utility - j * step))\n",
        "\n",
        "        for j in range(m):\n",
        "            candidate = ranking[j]\n",
        "\n",
        "            if j == 0:\n",
        "                if j + 1 < m:\n",
        "                    lower_bound = base_utilities[ranking[j+1]] + 1\n",
        "                else:\n",
        "                    lower_bound = min_utility\n",
        "                upper_bound = max_utility\n",
        "            elif j == m - 1:\n",
        "                lower_bound = min_utility\n",
        "                upper_bound = base_utilities[ranking[j-1]] - 1\n",
        "            else:\n",
        "                lower_bound = base_utilities[ranking[j+1]] + 1\n",
        "                upper_bound = base_utilities[ranking[j-1]] - 1\n",
        "\n",
        "            noise_range = min(utility_noise, (upper_bound - lower_bound) // 2)\n",
        "            if noise_range > 0:\n",
        "                noise = np.random.randint(-noise_range, noise_range + 1)\n",
        "                utilities[i, candidate] = max(lower_bound, min(upper_bound, base_utilities[candidate] + noise))\n",
        "            else:\n",
        "                utilities[i, candidate] = base_utilities[candidate]\n",
        "\n",
        "        for j in range(m-1):\n",
        "            if utilities[i, ranking[j]] <= utilities[i, ranking[j+1]]:\n",
        "                utilities[i, ranking[j]] = utilities[i, ranking[j+1]] + 1\n",
        "\n",
        "    return utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OwgMazpxWvb"
      },
      "outputs": [],
      "source": [
        "# Experiment settings\n",
        "n_values = [5, 10, 20, 30, 50, 70, 100, 150]\n",
        "m_k_pairs = [\n",
        "    (10, 2), (10, 4),\n",
        "    (20, 2), (20, 4), (20, 5),\n",
        "    (30, 2), (30,4), (30, 5), (30, 10),\n",
        "    (50, 5), (50, 10), (50, 12), (50, 15),\n",
        "    (80, 10), (80, 12), (80, 15), (80, 20), (80, 30),\n",
        "    (100, 12), (100, 15), (100, 20), (100, 30),\n",
        "    (120, 15), (120, 20), (120,30), (120, 40),\n",
        "    (150, 20), (150, 30), (150, 40),\n",
        "    (200, 20), (200, 30), (200, 40)]\n",
        "\n",
        "phi_values = [0.2, 0.4, 0.6, 0.8, 1]\n",
        "max_utility = 200\n",
        "min_utility = 0\n",
        "utility_noise = 50\n",
        "seed_values = range(0, 10)\n",
        "\n",
        "all_results = []\n",
        "\n",
        "def run_experiment_three_C():\n",
        "    for n in n_values:\n",
        "        readable_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
        "        logging.info(f\"{Fore.BLACK}Start time: {readable_time} -------> N Value = {n}{Style.RESET_ALL}\")\n",
        "        for (m, k), phi in itertools.product(m_k_pairs, phi_values):\n",
        "            for seed in seed_values:\n",
        "                utils = create_mallows_utilities_normalized(n, m, phi=phi, max_utility=max_utility, min_utility=min_utility,\n",
        "                                                 utility_noise=utility_noise, seed=seed)\n",
        "\n",
        "                result = compare_algorithms([k], [seed], n, m, phi, max_utility, utils)\n",
        "\n",
        "                for alg in result[k]:\n",
        "                    metrics = result[k][alg]\n",
        "                    all_results.append({\n",
        "                        \"n\": n, \"m\": m, \"k\": k, \"phi\": phi, \"seed\": seed, \"algorithm\": alg,\n",
        "                        \"Avg Satisfaction\": np.mean(metrics[\"Avg Satisfaction\"]),\n",
        "                        \"Avg Satisfaction std\": np.std(metrics[\"Avg Satisfaction\"]),\n",
        "                        \"Exclusion Ratio\": np.mean(metrics[\"Exclusion Ratio\"]),\n",
        "                        \"Exclusion Ratio std\": np.std(metrics[\"Exclusion Ratio\"]),\n",
        "                        \"Gini\": np.mean(metrics[\"Gini\"]),\n",
        "                        \"Gini std\": np.std(metrics[\"Gini\"]),\n",
        "                        \"10th Percentile\": np.mean(metrics[\"10th Percentile\"]),\n",
        "                        \"10th Percentile std\": np.std(metrics[\"10th Percentile\"]),\n",
        "                        \"15th Percentile\": np.mean(metrics[\"15th Percentile\"]),\n",
        "                        \"15th Percentile std\": np.std(metrics[\"15th Percentile\"]),\n",
        "                        \"25th Percentile\": np.mean(metrics[\"25th Percentile\"]),\n",
        "                        \"25th Percentile std\": np.std(metrics[\"25th Percentile\"]),\n",
        "                        \"m/k\": m / k,\n",
        "                        \"k/n\": k / n\n",
        "                    })\n",
        "\n",
        "    # Generate all plots\n",
        "    plot_metrics_against_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWeMSQoexWvb"
      },
      "source": [
        "# Experiment 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kLSwTHcnq9t"
      },
      "outputs": [],
      "source": [
        "def create_polarized_instance(n_voters, m_candidates, x_fraction, coh2, instance_seed):\n",
        "    \"\"\"\n",
        "    Creates a polarized society with two groups.\n",
        "    Group 1: Size x * n, approves first half of candidates.\n",
        "    Group 2: Remainder, approves a random subset of the second half (controlled by coh2).\n",
        "    \"\"\"\n",
        "    original_state = random.getstate()\n",
        "    random.seed(instance_seed)\n",
        "    \n",
        "    assert m_candidates % 2 == 0\n",
        "    group_1_size = int(n_voters * x_fraction)\n",
        "    group_2_size = n_voters - group_1_size\n",
        "    \n",
        "    utils = np.zeros((n_voters, m_candidates), dtype=int)\n",
        "    \n",
        "    # Group 1 preferences\n",
        "    utils[:group_1_size, :m_candidates // 2] = 1\n",
        "    \n",
        "    # Group 2 preferences\n",
        "    for i in range(group_2_size):\n",
        "        num_approved = int(coh2 * (m_candidates // 2))\n",
        "        approved = random.sample(range(m_candidates // 2, m_candidates), num_approved)\n",
        "        for j in approved:\n",
        "            utils[group_1_size + i, j] = 1\n",
        "            \n",
        "    random.setstate(original_state)\n",
        "    return utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJJl7WCPpcpA"
      },
      "outputs": [],
      "source": [
        "def run_experiment_four(num_random_profiles_to_test=300, max_num_seeds=10):\n",
        "    seeds = range(0, max_num_seeds)\n",
        "    num_random_profiles = num_random_profiles_to_test\n",
        "\n",
        "    underperformance_counts = {\n",
        "        'Greedy Budgeting': 0,\n",
        "        'Online MES': 0,\n",
        "        'Online BOS': 0,\n",
        "        'Online Nash Rule': 0\n",
        "    }\n",
        "    underperformance_total_gap = {\n",
        "        'Greedy Budgeting': 0,\n",
        "        'Online MES': 0,\n",
        "        'Online BOS': 0,\n",
        "        'Online Nash Rule': 0\n",
        "    }\n",
        "    underperformance_max_gap = {\n",
        "        'Greedy Budgeting': 0,\n",
        "        'Online MES': 0,\n",
        "        'Online BOS': 0,\n",
        "        'Online Nash Rule': 0\n",
        "    }\n",
        "\n",
        "    deficit_per_instance = {\n",
        "        'Greedy Budgeting': [],\n",
        "        'Online MES': [],\n",
        "        'Online BOS': [],\n",
        "        'Online Nash Rule': []\n",
        "    }\n",
        "\n",
        "    for round_num in range(num_random_profiles):\n",
        "        random.seed(round_num)\n",
        "        np.random.seed(round_num)\n",
        "\n",
        "        if round_num % 50 == 0:\n",
        "            readable_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
        "            logging.info(f\"{Fore.BLACK}Start time: {readable_time} -------> Round Number = {round_num+1}{Style.RESET_ALL}\")\n",
        "\n",
        "        n = random.choice(range(5, 200))\n",
        "        m = random.choice(range(16, 300, 2))\n",
        "        k = random.choice(range(3, int(m/4)))\n",
        "        x = round(random.uniform(0.1, 0.9), 2)\n",
        "        coh2 = round(random.uniform(0.1, 0.9), 2)\n",
        "\n",
        "        utils = create_polarized_instance(n, m, x, coh2, round_num)\n",
        "        group1 = set(range(m // 2))\n",
        "        avg_opt = math.floor((math.floor(int(n * x)) / n) * k)\n",
        "\n",
        "        g1_mes = []\n",
        "        g1_bos = []\n",
        "        g1_greedy = []\n",
        "        g1_submod = []\n",
        "\n",
        "        for seed in seeds:\n",
        "            mes_sel = online_mes(utils, k, seed, 'utilitarian_greedy')\n",
        "            bos_sel = online_bos(utils, k, seed)\n",
        "            greedy_sel = greedy(utils, k, seed)\n",
        "            projects_list, voters_list, votes = convert_matrix_utils(utils, \"SubmodularSecretary\")\n",
        "            submod_sel = monotone_submodular_secretary(k, projects_list, voters_list, votes, vote_type=\"Approval\", seed=seed)\n",
        "\n",
        "            g1_mes.append(sum(1 for c in mes_sel if c in group1))\n",
        "            g1_bos.append(sum(1 for c in bos_sel if c in group1))\n",
        "            g1_greedy.append(sum(1 for c in greedy_sel if c in group1))\n",
        "            g1_submod.append(sum(1 for c in submod_sel if c in group1))\n",
        "        for name, counts in [('Online MES', g1_mes), ('Online BOS', g1_bos), ('Greedy Budgeting', g1_greedy), ('Online Nash Rule', g1_submod)]:\n",
        "            avg_val = np.mean(counts)\n",
        "            if avg_val < avg_opt:\n",
        "                underperformance_counts[name] += 1\n",
        "                deficit = avg_opt - avg_val\n",
        "                underperformance_total_gap[name] += deficit\n",
        "                deficit_per_instance[name].append(deficit)\n",
        "                underperformance_max_gap[name] = max(underperformance_max_gap[name], deficit)\n",
        "\n",
        "    underperformance_percentage = {\n",
        "        method: (underperformance_counts[method] / num_random_profiles) * 100\n",
        "        for method in underperformance_counts\n",
        "    }\n",
        "\n",
        "    avg_deficit_per_instance = {\n",
        "        method: (underperformance_total_gap[method] / underperformance_counts[method])\n",
        "        if underperformance_counts[method] > 0 else 0\n",
        "        for method in underperformance_counts\n",
        "    }\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    methods = list(underperformance_counts.keys())\n",
        "    percentages = [underperformance_percentage[m] for m in methods]\n",
        "    plt.bar(methods, percentages, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#6C3BAA'])\n",
        "    plt.title(\"Percentage of Instances Below avg_opt\")\n",
        "    plt.ylabel(\"Percentage of Total Profiles (%)\")\n",
        "    plt.grid(axis='y')\n",
        "    plt.show()\n",
        "\n",
        "    logging.info(f\"{Fore.BLUE}Percentage of underperformance:\")\n",
        "    for method, percentage in zip(methods, percentages):\n",
        "        logging.info(f\"{Fore.YELLOW}{method}: {Fore.WHITE}{percentage:.2f}%\")\n",
        "\n",
        "    max_deficits = [underperformance_max_gap[m] for m in methods]\n",
        "    avg_deficits = [avg_deficit_per_instance[m] for m in methods]\n",
        "\n",
        "    x = np.arange(len(methods))\n",
        "    width = 0.35  # Bar width\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    rects1 = ax.bar(x - width/2, avg_deficits, width, label='Average Deficit', color='#ffdb0e')\n",
        "    rects2 = ax.bar(x + width/2, max_deficits, width, label='Maximum Deficit', color='#8c3b04')\n",
        "\n",
        "    ax.set_ylabel('Deficit')\n",
        "    ax.set_title('Avg and Max Deficit per Instance Below avg_opt')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(methods)\n",
        "    ax.legend()\n",
        "\n",
        "    plt.grid(axis='y')\n",
        "    plt.show()\n",
        "\n",
        "    logging.info(f\"{Fore.YELLOW}Average {Fore.WHITE}and {Fore.RED}Maximum deficits:\")\n",
        "    for m, avg, mx in zip(methods, avg_deficits, max_deficits):\n",
        "        logging.info(f\"{Fore.WHITE}{m} - {Fore.YELLOW}Avg: {avg:.4f}  {Fore.RED}Max: {mx:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
